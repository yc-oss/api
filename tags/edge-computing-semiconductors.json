[
  {
    "id": 12737,
    "name": "Tensil",
    "slug": "tensil",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/3aefe6d1c4f47d9ef26a3296e1724c3efe9bd5ac.png",
    "website": "https://www.tensil.ai",
    "all_locations": "San Francisco, CA, USA; Remote",
    "long_description": "Tensil automates machine learning hardware accelerator design. Our goal is to enable ML in every device. We've developed an algorithm that can design the best hardware accelerator for your machine learning model, unlocking 10x better performance per watt-dollar than GPUs and other hardware accelerators. Our technology enables our customers to create unbeatable products with Tensil custom hardware at the core.",
    "one_liner": "We turn machine learning models into custom hardware.",
    "team_size": 2,
    "industry": "Industrials",
    "subindustry": "Industrials -> Manufacturing and Robotics",
    "launched_at": 1557445614,
    "tags": [
      "Edge Computing Semiconductors",
      "Hardware",
      "Open Source",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2019",
    "status": "Inactive",
    "industries": [
      "Industrials",
      "Manufacturing and Robotics"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/tensil",
    "api": "https://yc-oss.github.io/api/batches/summer-2019/tensil.json"
  },
  {
    "id": 29747,
    "name": "deepsilicon",
    "slug": "deepsilicon",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/86bf1a250ebd174788e945f8cb80bbfa5fad5a1c.png",
    "website": "https://www.deepsilicon.net/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "",
    "one_liner": "Software and hardware to run neural networks faster and cheaper",
    "team_size": 2,
    "industry": "Industrials",
    "subindustry": "Industrials",
    "launched_at": 1724647478,
    "tags": [
      "Edge Computing Semiconductors",
      "Hard Tech",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2024",
    "status": "Inactive",
    "industries": [
      "Industrials"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/deepsilicon",
    "api": "https://yc-oss.github.io/api/batches/summer-2024/deepsilicon.json"
  },
  {
    "id": 30284,
    "name": "Exla",
    "slug": "exla",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/94cd00784e37842fc455ee2fd7b22d487b0693cf.png",
    "website": "https://exla.ai/",
    "all_locations": "",
    "long_description": "Exla aggressively quantizes AI models to minimize memory usage and maximize inference speed. Whether you're deploying LLMs, VLMs, VLAs, or custom models, Exla reduces memory footprint by up to 80% and accelerates inference by 3â€“20x - all with just a few lines of code.\r\n\r\nhttps://cal.com/exla-ai/schedule",
    "one_liner": "An SDK to run transformer models anywhere",
    "team_size": 0,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1740012412,
    "tags": [
      "Edge Computing Semiconductors",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/exla",
    "api": "https://yc-oss.github.io/api/batches/winter-2025/exla.json"
  },
  {
    "id": 30676,
    "name": "Stellon Labs",
    "slug": "stellon-labs",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/e0f795844bb7b220e603390ba0b9ce967fb6db26.png",
    "website": "https://stellonlabs.com/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Stellon Labs is an AI research lab that is building tiny frontier AI models that can run on edge devices like smartphones, wearables and embedded systems. Our first open source model, KittenTTS, is a super-tiny text-to-speech model, that got 8K Github stars and 45K model downloads within 2 weeks of launching. ",
    "one_liner": "Building tiny frontier AI models that run on edge devices",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1755664851,
    "tags": [
      "Artificial Intelligence",
      "Edge Computing Semiconductors"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/stellon-labs",
    "api": "https://yc-oss.github.io/api/batches/summer-2025/stellon-labs.json"
  }
]
