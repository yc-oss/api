[
  {
    "id": 12737,
    "name": "Tensil",
    "slug": "tensil",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/3aefe6d1c4f47d9ef26a3296e1724c3efe9bd5ac.png",
    "website": "https://www.tensil.ai",
    "all_locations": "San Francisco, CA, USA; Remote",
    "long_description": "Tensil automates machine learning hardware accelerator design. Our goal is to enable ML in every device. We've developed an algorithm that can design the best hardware accelerator for your machine learning model, unlocking 10x better performance per watt-dollar than GPUs and other hardware accelerators. Our technology enables our customers to create unbeatable products with Tensil custom hardware at the core.",
    "one_liner": "We turn machine learning models into custom hardware.",
    "team_size": 2,
    "industry": "Industrials",
    "subindustry": "Industrials -> Manufacturing and Robotics",
    "launched_at": 1557445614,
    "tags": [
      "Edge Computing Semiconductors",
      "Hardware",
      "Open Source",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2019",
    "status": "Inactive",
    "industries": [
      "Industrials",
      "Manufacturing and Robotics"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/tensil",
    "api": "https://yc-oss.github.io/api/batches/summer-2019/tensil.json"
  },
  {
    "id": 29747,
    "name": "deepsilicon",
    "slug": "deepsilicon",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/86bf1a250ebd174788e945f8cb80bbfa5fad5a1c.png",
    "website": "https://www.deepsilicon.net/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "",
    "one_liner": "Software and hardware to run neural networks faster and cheaper",
    "team_size": 2,
    "industry": "Industrials",
    "subindustry": "Industrials",
    "launched_at": 1724647478,
    "tags": [
      "Edge Computing Semiconductors",
      "Hard Tech",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2024",
    "status": "Inactive",
    "industries": [
      "Industrials"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/deepsilicon",
    "api": "https://yc-oss.github.io/api/batches/summer-2024/deepsilicon.json"
  },
  {
    "id": 30284,
    "name": "Exla",
    "slug": "exla",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/94cd00784e37842fc455ee2fd7b22d487b0693cf.png",
    "website": "https://exla.ai/",
    "all_locations": "",
    "long_description": "Exla aggressively quantizes AI models to minimize memory usage and maximize inference speed. Whether you're deploying LLMs, VLMs, VLAs, or custom models, Exla reduces memory footprint by up to 80% and accelerates inference by 3â€“20x - all with just a few lines of code.\r\n\r\nhttps://cal.com/exla-ai/schedule",
    "one_liner": "An SDK to run transformer models anywhere",
    "team_size": 0,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1740012412,
    "tags": [
      "Edge Computing Semiconductors",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/exla",
    "api": "https://yc-oss.github.io/api/batches/winter-2025/exla.json"
  },
  {
    "id": 30656,
    "name": "DeepGrove",
    "slug": "deepgrove",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/59526ba018b33a62299943322dc03eae29a298f4.png",
    "website": "",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Developing the next suite of 1-bit foundation models that can run on edge devices.",
    "one_liner": "Frontier Intelligence. On Any Device.",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "Unspecified",
    "launched_at": 1753646840,
    "tags": [
      "Artificial Intelligence",
      "Deep Learning",
      "Edge Computing Semiconductors",
      "IoT"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2025",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/deepgrove",
    "api": "https://yc-oss.github.io/api/batches/summer-2025/deepgrove.json"
  }
]
