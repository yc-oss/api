[
  {
    "id": 30,
    "name": "Matterport",
    "slug": "matterport",
    "former_names": [
      "MatterPort"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b271a79c3b59d6344c90e2803525a22f2a5e8406.png",
    "website": "http://matterport.com",
    "all_locations": "Sunnyvale, CA, USA",
    "long_description": "Matterport is an immersive media technology company that is shaking up the 3D / VR world.  Our team has built the first end-to-end system for creating, modifying, distributing, and navigating immersive 3D and virtual reality (VR) versions of real-world spaces on web and mobile devices. Matterport offers the world's most inexpensive and simplest way to capture 3D spaces. \r\n\r\nOur products include:\r\n- Matterport Pro Camera for capturing real spaces in 3D.  It collects accurate visual and spatial data to map entire areas in minutes and is all about automation and ease of use.\r\n- The Matterport Cloud for processing and hosting 3D models\r\n- Matterport Portal, our system for viewing, editing, and managing models; collaborating with colleagues; and sharing models with others\r\n- Matterport 3D Showcase, a browser-based 3D media player, which allows anyone to view 3D models in their browser with no additional software\r\n- Matterport Core VR: All Spaces can be converted to VR and experienced on Samsung Gear VR or Google Cardboard (in beta), with additional device support coming soon.\r\n\r\nMatterport 3D media solutions power industries from real estate (residential, multi-family and commercial) and travel and hospitality (hotels, vacation rentals, and venue booking), to business listings, architecture, engineering and construction, news and entertainment, and everything in between. \r\n\r\nWe’re growing fast. If you’re passionate about solving cutting-edge problems in computer vision and hardware design and creating order-of-magnitude improvements in the ability to easily create and share 3D models of real world spaces, we want to talk to you. See open positions at matterport.com/jobs.\r\n\r\nTry Matterport for yourself at matterport.com/try.",
    "one_liner": "Turn physical objects and environments into 3D models in seconds.",
    "team_size": 201,
    "industry": "Consumer",
    "subindustry": "Consumer -> Virtual and Augmented Reality",
    "launched_at": 1322045771,
    "tags": [
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": true,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2012",
    "status": "Public",
    "industries": [
      "Consumer",
      "Virtual and Augmented Reality"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/matterport",
    "api": "https://yc-oss.github.io/api/batches/winter-2012/matterport.json"
  },
  {
    "id": 50,
    "name": "Flutter",
    "slug": "flutter",
    "former_names": [],
    "small_logo_thumb_url": "/company/thumb/missing.png",
    "website": "http://flutterapp.com",
    "all_locations": "Santa Monica, CA, USA",
    "long_description": "Flutter is recreating the magic of seeing someone in real-life for the first time, on your phone.\n\nFlutter lets you record short, ephemeral videos to express yourself and capture the attention of potential matches nearby. Users browse through nearby videos and, just like Tinder, like or pass on each one before moving on to the next.\n\nHere’s the catch: to actually match with someone, you have to be on the app at the same time and look into each other’s eyes for 15 seconds to see if there’s a spark. We help users play this game by sending push notifications when people they like are online.\n\nVideo is so powerful. We've seen this with YouTube, Snapchat, Meerkat. And 15 seconds of live, two-way video can tell you so much more about a person than hand-picked photos and bios.",
    "one_liner": "Flutter combined computer vision technology with the built-in webcams…",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1322045950,
    "tags": [
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2012",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/flutter",
    "api": "https://yc-oss.github.io/api/batches/winter-2012/flutter.json"
  },
  {
    "id": 175,
    "name": "SimplyListed",
    "slug": "simplylisted",
    "former_names": [],
    "small_logo_thumb_url": "/company/thumb/missing.png",
    "website": "http://simplylisted.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "SimplyListed makes it really easy for people to sell their stuff. You just take a picture, and they list your item for sale automatically.\r\n\r\nA prototype of the SimplyListed iPhone app was first released on the iTunes App Store in February 2011.",
    "one_liner": "Sell your stuff.",
    "team_size": 2,
    "industry": "Consumer",
    "subindustry": "Consumer -> Home and Personal",
    "launched_at": 1326790047,
    "tags": [
      "Marketplace",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2011",
    "status": "Inactive",
    "industries": [
      "Consumer",
      "Home and Personal"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/simplylisted",
    "api": "https://yc-oss.github.io/api/batches/winter-2011/simplylisted.json"
  },
  {
    "id": 193,
    "name": "GazeHawk",
    "slug": "gazehawk",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/7b6bb6a40cbe23dd398442068cb5d69e8e784f57.png",
    "website": "http://gazehawk.com",
    "all_locations": "Mountain View, CA, USA",
    "long_description": "GazeHawk provides low-cost eye tracking technology for use in usability studies and ad evaluation.  Our proprietary technology allows us to use ordinary webcams to run studies.  This enables in-home eye tracking, as well as fast, affordable large-scale studies.http://www.gazehawk.com/",
    "one_liner": "Eyetracking using webcams.",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1326790180,
    "tags": [
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2010",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/gazehawk",
    "api": "https://yc-oss.github.io/api/batches/summer-2010/gazehawk.json"
  },
  {
    "id": 679,
    "name": "VizeraLabs",
    "slug": "vizeralabs",
    "former_names": [],
    "small_logo_thumb_url": "/company/thumb/missing.png",
    "website": "http://vizeralabs.com",
    "all_locations": "Sunnyvale, CA, USA",
    "long_description": "Vizera was an augmented reality company that used projectors with depth sensors to project an AR layer onto real world objects, rather than using screens/smart glasses. \r\n\r\nOur first application was in retail where we partnered with top furniture retailers to display their selection of different fabrics/patterns by using our projectors in their smaller showrooms to improve their in store revenue. \r\n\r\nOur demo is still live on YouTube: https://www.youtube.com/watch?v=5YV8lo-OxZQ ",
    "one_liner": "Augmented reality through projectors",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1398907794,
    "tags": [
      "Augmented Reality",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2014",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/vizeralabs",
    "api": "https://yc-oss.github.io/api/batches/summer-2014/vizeralabs.json"
  },
  {
    "id": 822,
    "name": "Dabble",
    "slug": "dabble",
    "former_names": [
      "Perceptiv Labs",
      "Vertical",
      "Placenote"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/ded86f0a0f49180c787803bef08563dd167f5851.png",
    "website": "https://dabble.so",
    "all_locations": "Toronto, ON, Canada; Remote",
    "long_description": "Dabble is a virtual photo studio for e-commerce powered by hyper-realistic CGI and computer vision. The demand for content in retail is skyrocketing due to the pandemic induced surge in online shopping, but product photography is still extremely slow, tedious and expensive. We’re building a platform to scale and automate product photography for every e-commerce brand.",
    "one_liner": "A synthetic photo studio for e-commerce",
    "team_size": 3,
    "industry": "B2B",
    "subindustry": "B2B -> Marketing",
    "launched_at": 1416309244,
    "tags": [
      "Artificial Intelligence",
      "Augmented Reality",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2015",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Marketing"
    ],
    "regions": [
      "Canada",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/dabble",
    "api": "https://yc-oss.github.io/api/batches/winter-2015/dabble.json"
  },
  {
    "id": 832,
    "name": "Standard Cyborg",
    "slug": "standard-cyborg",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/ea641cf296beace7a7288415d4808dc519f3a987.png",
    "website": "http://standardcyborg.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "We are multiplying the potential of the real world by making computer vision accessible to all.\r\n\r\nWe create the cloud and edge tools that developers and non-developers require in order to build, deploy, and improve CV solutions quickly.\r\n\r\nstandardcyborg.com (YC W15)",
    "one_liner": "Buid, test and deploy perception applications",
    "team_size": 9,
    "industry": "Healthcare",
    "subindustry": "Healthcare -> Medical Devices",
    "launched_at": 1416310916,
    "tags": [
      "Machine Learning",
      "Computer Vision",
      "Open Source"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2015",
    "status": "Inactive",
    "industries": [
      "Healthcare",
      "Medical Devices"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/standard-cyborg",
    "api": "https://yc-oss.github.io/api/batches/winter-2015/standard-cyborg.json"
  },
  {
    "id": 856,
    "name": "Mashgin",
    "slug": "mashgin",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/bd7ff2b3db9bbbc82a79afababdad873d16b6e54.png",
    "website": "http://mashgin.com",
    "all_locations": "Palo Alto, CA, USA",
    "long_description": "Mashgin creates better retail experiences through visual automation. \r\n\r\nWe’ve built a self-checkout kiosk that uses computer vision to scan multiple items without barcodes, reducing checkout time by 10x. We’re completely recreating the checkout experience in an industry that’s had little innovation in decades.\r\n\r\nOur clients see dramatic reductions in lines and revenue increases of as much as 400% as a result.",
    "one_liner": "Self-Checkout using Computer Vision.",
    "team_size": 75,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1421189374,
    "tags": [
      "Cashierless Checkout",
      "Deep Learning",
      "Hardware",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2015",
    "status": "Active",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/mashgin",
    "api": "https://yc-oss.github.io/api/batches/winter-2015/mashgin.json"
  },
  {
    "id": 929,
    "name": "Prayas Analytics",
    "slug": "prayas-analytics",
    "former_names": [
      "Prayas Analytics MetricBoy",
      "SimpleMoney"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/5239f1a49fa06d125e98d56bb9e5a5fd04d9f05a.png",
    "website": "http://prayasanalytics.com",
    "all_locations": "New York, NY, USA",
    "long_description": "Prayas Anaytics helped retailers A/B test their stores, the way eCommerce companies A/B test their websites. We did this by continuously collecting data on customer movement using existing security cameras already in a retailer's stores. \r\n\r\nWe were a Y Combinator backed company (S15) and worked with several retailers including Barneys, Payomatic, and multiple Fortune 200 retailers.",
    "one_liner": "A/B testing for brick-and-mortar stores.",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1430156128,
    "tags": [
      "SaaS",
      "Computer Vision",
      "Retail Tech"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2015",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/prayas-analytics",
    "api": "https://yc-oss.github.io/api/batches/summer-2015/prayas-analytics.json"
  },
  {
    "id": 933,
    "name": "Reduced Energy Microsystems",
    "slug": "reduced-energy-microsystems",
    "former_names": [],
    "small_logo_thumb_url": "/company/thumb/missing.png",
    "website": "http://remicro.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Reduced Energy Microsystems is building the most power-efficient silicon for embedded computer vision to bring visual intelligence to a whole new range of devices. By combining  proprietary asynchronous resilient technology with a custom neural network architecture, REM chips will handle state-of-the-art inference and traditional vision workloads in a tiny power envelope. REM makes  augmented reality, body-worn cameras, and autonomous robots smarter than ever before.",
    "one_liner": "Building the lowest-power silicon for embedded deep learning and…",
    "team_size": 2,
    "industry": "Industrials",
    "subindustry": "Industrials -> Manufacturing and Robotics",
    "launched_at": 1430156130,
    "tags": [
      "Artificial Intelligence",
      "Hardware",
      "Computer Vision",
      "Energy"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2015",
    "status": "Inactive",
    "industries": [
      "Industrials",
      "Manufacturing and Robotics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/reduced-energy-microsystems",
    "api": "https://yc-oss.github.io/api/batches/summer-2015/reduced-energy-microsystems.json"
  },
  {
    "id": 936,
    "name": "Shape (ShapeScale)",
    "slug": "shape-shapescale",
    "former_names": [
      "ShapeScale"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/51a78fd63bb7c35e64c4b0654f44569b121ca09b.png",
    "website": "https://shapescale.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Shape is a health tech startup based in San Francisco, California. We are backed by Y Combinator and the company is led by experienced hardware serial entrepreneurs. Shape has designed a product called ShapeScale. ShapeScale is transforming the way we measure our health goals by enabling you to visualize yourself in 3D and see where you have been losing fat and gaining muscle.",
    "one_liner": "ShapeScale is a personal 3D scanner and fitness tracker that…",
    "team_size": 7,
    "industry": "Consumer",
    "subindustry": "Consumer -> Consumer Electronics",
    "launched_at": 1430156131,
    "tags": [
      "Hardware",
      "Computer Vision",
      "Consumer Health Services"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2015",
    "status": "Active",
    "industries": [
      "Consumer",
      "Consumer Electronics"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/shape-shapescale",
    "api": "https://yc-oss.github.io/api/batches/summer-2015/shape-shapescale.json"
  },
  {
    "id": 999,
    "name": "Focal Systems",
    "slug": "focal-systems",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/e25ba04ae8686807d958c48f1372502741b4b2e3.png",
    "website": "http://www.focal.systems",
    "all_locations": "New York, NY, USA; San Francisco, CA, USA; Toronto, ON, Canada; London, England, United Kingdom",
    "long_description": "Focal Systems is on a mission to lower the cost of living for all mankind by automating and optimizing Brick and Mortar Retail with the latest advancements in AI. Focal Systems is the industry leader in retail automation solutions. By digitizing store shelves hourly and unleashing FocalOS, retailers unlock huge operational efficiencies, optimized merchandising, and streamlined supply chains which deliver impactful financial results. Focal is transforming retail by empowering store management to make automated, data-driven decisions. We are the operating system of retail.",
    "one_liner": "Building the Operating System for B&M Retail using Deep Learning",
    "team_size": 170,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1447280416,
    "tags": [
      "Deep Learning",
      "Grocery",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2016",
    "status": "Active",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "Canada",
      "United Kingdom",
      "America / Canada",
      "Europe",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/focal-systems",
    "api": "https://yc-oss.github.io/api/batches/winter-2016/focal-systems.json"
  },
  {
    "id": 1058,
    "name": "Caper",
    "slug": "caper",
    "former_names": [
      "QueueHop"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/45034c22d81491a4e49c2c46c3c822d2d820941d.png",
    "website": "https://www.caper.ai/",
    "all_locations": "",
    "long_description": "Caper focuses on compacting Amazon-Go's technology (image recognition, sensor fusion and artificial intelligence) into a smart shopping cart, allowing each shopper to throw her groceries into the cart and self-checkout without cashiers. The technology is looking to fundamentally transform physical retail and rapidly scale into existing grocery stores.",
    "one_liner": "Plug-and-play cashier-less retail powered by computer vision and AI",
    "team_size": 15,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1447654816,
    "tags": [
      "Artificial Intelligence",
      "Cashierless Checkout",
      "Computer Vision",
      "Retail Tech"
    ],
    "tags_highlighted": [],
    "top_company": true,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2016",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/caper",
    "api": "https://yc-oss.github.io/api/batches/winter-2016/caper.json"
  },
  {
    "id": 1221,
    "name": "Iris Automation",
    "slug": "iris-automation",
    "former_names": [],
    "small_logo_thumb_url": "/company/thumb/missing.png",
    "website": "http://www.irisonboard.com",
    "all_locations": "San Francisco, CA, USA; Remote",
    "long_description": "The future for autonomous industrial drones is in sight - Enabling safer drone operation through intelligent collision avoidance. We are a Y Combinator and Silicon Valley investor company with a team from NASA, Boeing and PhDs in computer vision. \r\nRead more at: https://tinyurl.com/y7tm4zr8\r\n \r\nWebsite: www.IrisOnBoard.com",
    "one_liner": "Enabling autonomous drone operations globally through AI software",
    "team_size": null,
    "industry": "Industrials",
    "subindustry": "Industrials -> Drones",
    "launched_at": 1461210618,
    "tags": [
      "Drones",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2016",
    "status": "Acquired",
    "industries": [
      "Industrials",
      "Drones"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/iris-automation",
    "api": "https://yc-oss.github.io/api/batches/summer-2016/iris-automation.json"
  },
  {
    "id": 1285,
    "name": "CrowdAI",
    "slug": "crowdai",
    "former_names": [
      "StenoAI"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/65641ddd8516f01cc3bf87dd2c876cd999d398f0.png",
    "website": "https://crowdai.com/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "CrowdAI equips enterprises of all sizes with the power of deep learning and the approachability and speed of no-code software.  Our easy-to-master platform allows users of all technical abilities, from business operators to data scientists, to power real-time decisions from their visual world.\r\n\r\nRecognizing data as the new code, CrowdAI is the only vision AI platform to truly provide organizations with the infrastructure for the entire AI-lifecycle, empowering you to label data systematically, train models efficiently, scale models iteratively, and power decisions continuously.",
    "one_liner": "CrowdAI is the world's leading no-code platform for vision AI",
    "team_size": 32,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1461817213,
    "tags": [
      "Machine Learning",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2016",
    "status": "Acquired",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/crowdai",
    "api": "https://yc-oss.github.io/api/batches/summer-2016/crowdai.json"
  },
  {
    "id": 1487,
    "name": "Ambient.ai",
    "slug": "ambient-ai",
    "former_names": [
      "Ambient"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/624d0ce6f387431048bed692cfded210ffc7d139.png",
    "website": "https://ambient.ai",
    "all_locations": "San Jose, CA, USA",
    "long_description": "Ambient.ai is a computer vision intelligence company transforming enterprise security operations to prevent security incidents before they happen. The Ambient.ai platform applies AI and computer vision intelligence to existing sensor and camera infrastructure to deliver continuous physical security monitoring and automate the immediate dispatch of human resources. Ambient.ai is the first platform that goes beyond basic motion detection and image recognition to achieve near-human perception with automated situational context. \r\n\r\nWith physical security incidents on the rise and physical security organizations left under-resourced, Ambient.ai’s computer intelligence platform comes at a time of critical need, which is why the company has raised over $50 million from venture capital investors led by a16z. Today, large enterprises, schools and organizations – including many of the largest US tech companies and other Fortune 500 companies – use Ambient.ai to secure property, people, and assets from the most harrowing physical security threats.\r\n\r\nThe company was founded in 2017 by experts in artificial intelligence from Stanford who previously built iconic products at Apple, Google, Microsoft and Dropbox. We are backed by Andreessen Horowitz (a16z), SV Angel, Y Combinator, and visionary angels like Jyoti Bansal, Mark Leslie and Elad Gil.",
    "one_liner": "AI company transforming enterprise physical security to prevent…",
    "team_size": 95,
    "industry": "B2B",
    "subindustry": "B2B -> Security",
    "launched_at": 1478224835,
    "tags": [
      "Computer Vision",
      "Security",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2017",
    "status": "Active",
    "industries": [
      "B2B",
      "Security"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/ambient-ai",
    "api": "https://yc-oss.github.io/api/batches/winter-2017/ambient-ai.json"
  },
  {
    "id": 1498,
    "name": "Veryfi, Inc.",
    "slug": "veryfi-inc",
    "former_names": [
      "IQB Labs",
      "IQBoxy",
      "Veryfi"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b363a44bfe1278786c4092bd157ce82f208e1a21.png",
    "website": "https://www.veryfi.com/",
    "all_locations": "San Mateo, CA, USA",
    "long_description": "Veryfi's cutting-edge multimodal AI transforms documents into structured data with unparalleled accuracy, bulletproof privacy, and lightning-fast speed. Experience the power of data extraction, fraud detection & product intelligence.\r\n\r\nVeryfi gives you a fully integrated suite of data transformation products for you to securely capture, extract and transform bills, receipts and any other documents into structured data for use in your app, website or backoffice. To learn more https://www.veryfi.com/",
    "one_liner": "APIs to Transform Documents into Structured Data",
    "team_size": 70,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1478227238,
    "tags": [
      "Artificial Intelligence",
      "Computer Vision",
      "API",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2017",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/veryfi-inc",
    "api": "https://yc-oss.github.io/api/batches/winter-2017/veryfi-inc.json"
  },
  {
    "id": 1557,
    "name": "Mirror AI",
    "slug": "mirror-ai",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/410226e6cc4a405060b8845ca57a12726472ea14.png",
    "website": "http://mirror-ai.com",
    "all_locations": "San Francisco, CA, USA; Remote",
    "long_description": "Mirror Emoji Keyboard by Mirror AI is an app that takes a photo of your face and creates you a set of personalized emoji. You get hundreds of them ready to be shared on messengers or social networks.",
    "one_liner": "App that turns selfie photos into thousand emoji that look like you…",
    "team_size": 7,
    "industry": "Consumer",
    "subindustry": "Consumer -> Social",
    "launched_at": 1481775630,
    "tags": [
      "Computer Vision",
      "Entertainment"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2017",
    "status": "Active",
    "industries": [
      "Consumer",
      "Social"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/mirror-ai",
    "api": "https://yc-oss.github.io/api/batches/winter-2017/mirror-ai.json"
  },
  {
    "id": 1583,
    "name": "Skyways",
    "slug": "skyways",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/6732fcb5c7c414475034015c2f1a9fa75a9f12a7.png",
    "website": "http://skyways.com",
    "all_locations": "Austin, TX, USA",
    "long_description": "",
    "one_liner": "Creating a new form of air transportation to advance our civilization",
    "team_size": 33,
    "industry": "Industrials",
    "subindustry": "Industrials -> Drones",
    "launched_at": 1493063490,
    "tags": [
      "Air Taxis",
      "Robotics",
      "Computer Vision",
      "AI",
      "ML"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2017",
    "status": "Active",
    "industries": [
      "Industrials",
      "Drones"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/skyways",
    "api": "https://yc-oss.github.io/api/batches/summer-2017/skyways.json"
  },
  {
    "id": 1858,
    "name": "Jido Maps",
    "slug": "jido-maps",
    "former_names": [
      "MapSync"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/788dc05b2141606cea9f6805759306ec0ea99f5e.png",
    "website": "https://jidomaps.com/",
    "all_locations": "Berkeley, CA, USA; San Francisco, CA, USA; Remote",
    "long_description": "We help teams that may or may not have machine learning expertise quickly turn their data into deployed computer vision models. Example applications include security camera monitoring, automating data entry, interpreting web scraped images, validated user photo inputs, augmented reality and mobile product scanning. \r\n\r\nIf you have visual or scanned data that you wish your software could interpret at scale, we can turn around a first proof of concept in under a week. Reach out and see how computer vision can change your business.",
    "one_liner": "Turn your data into a deployed computer vision model",
    "team_size": 6,
    "industry": "B2B",
    "subindustry": "B2B -> Infrastructure",
    "launched_at": 1512529341,
    "tags": [
      "Deep Learning",
      "Indoor Mapping",
      "Machine Learning",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2018",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Infrastructure"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/jido-maps",
    "api": "https://yc-oss.github.io/api/batches/winter-2018/jido-maps.json"
  },
  {
    "id": 1910,
    "name": "Activeloop",
    "slug": "activeloop",
    "former_names": [
      "Snark.ai",
      "Snark AI"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/c516ed5054847ecb1afb63f795f712b8d5c7f23d.png",
    "website": "https://activeloop.ai/",
    "all_locations": "Mountain View, CA, USA",
    "long_description": "We provide a simple API for creating, storing, versioning, and collaborating on multi-modal AI datasets of any size. With Activeloop's open-core stack, you can rapidly transform and stream data while training models at scale. Deep Lake powers foundational model training by acting as a vector database with significant benefits, such as (1) the ability to use multi-modal datasets to fine-tune your own LLM models, (2) storing both the embeddings and the original data with automatic version control, so no embedding re-computation is needed (3) truly serverless service with no vendor lock-in. How cool is that?\r\n\r\nGitHub loves us - we're one of the fastest-growing libraries there, and we're used by little-known companies like Google, Waymo, and Intel. No big deal. \r\n\r\nOur founding team hails from places like Princeton, Stanford, Google, and Tesla, and we're backed by Y Combinator & other Silicon Valley heavyweights. \r\n\r\nActiveloop is hiring, and we want you! Check out our open roles on our YC page and join the fun.\r\n\r\n10-min demo: https://activeloop.wistia.com/medias/aibvo0dst2\r\nWhitepaper: https://www.deeplake.ai/whitepaper",
    "one_liner": "Database for AI",
    "team_size": 15,
    "industry": "B2B",
    "subindustry": "B2B -> Infrastructure",
    "launched_at": 1524690140,
    "tags": [
      "Computational Storage",
      "Deep Learning",
      "Generative AI",
      "Computer Vision",
      "Open Source"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2018",
    "status": "Active",
    "industries": [
      "B2B",
      "Infrastructure"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/activeloop",
    "api": "https://yc-oss.github.io/api/batches/summer-2018/activeloop.json"
  },
  {
    "id": 1945,
    "name": "LabelFlow",
    "slug": "labelflow",
    "former_names": [
      "Sterblue"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/799423cdb14bc1fbe4eb1d647eedf74d0a22e8c7.png",
    "website": "https://labelflow.ai/",
    "all_locations": "Nantes, Pays de la Loire, France; Remote",
    "long_description": "At LabelFlow, we build GitHub for visual data. Our mission is to facilitate and accelerate the development of AI at scale thanks to top-notch labeling tools and a dataset marketplace.",
    "one_liner": "GitHub for visual data",
    "team_size": 6,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1525147499,
    "tags": [
      "Computer Vision",
      "Data Engineering",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2018",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "France",
      "Europe",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/labelflow",
    "api": "https://yc-oss.github.io/api/batches/summer-2018/labelflow.json"
  },
  {
    "id": 11895,
    "name": "Overview",
    "slug": "overview",
    "former_names": [
      "Overview.ai"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/cd1326e4f02e779f1009ae931cfeb26eb1eb20b7.png",
    "website": "https://overview.ai",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Here’s a secret between you and me: even the world’s largest manufacturers, companies like Tesla and Toyota, waste billions of dollars every year making products with quality issues. Building high-quality things at scale is incredibly hard. It doesn’t just happen because you hire smart people or buy good machines. It requires seeing problems early, understanding them deeply, and acting in real time, something factories were never designed to do.\r\n\r\nAt Overview.ai, we’re changing that. We build custom hardware, edge AI, and software systems that give manufacturers real visibility into how their products are actually being made. Our technology helps catch defects earlier, reduce waste, and fundamentally improve how factories operate. This work matters, not just for our customers, but for keeping American manufacturing competitive in a world that’s moving faster every year.",
    "one_liner": "Reshaping industrial quality with AI, hardware, and software",
    "team_size": 40,
    "industry": "Industrials",
    "subindustry": "Industrials -> Manufacturing and Robotics",
    "launched_at": 1538509310,
    "tags": [
      "Deep Learning",
      "IoT",
      "Computer Vision",
      "Manufacturing",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2019",
    "status": "Active",
    "industries": [
      "Industrials",
      "Manufacturing and Robotics"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/overview",
    "api": "https://yc-oss.github.io/api/batches/winter-2019/overview.json"
  },
  {
    "id": 11961,
    "name": "Sorting Robotics",
    "slug": "sorting-robotics",
    "former_names": [
      "Robotic Sorting Solutions"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/2dfc5eeb06e8051af24bd5a9c7758dbe219fba21.png",
    "website": "https://www.sortingrobotics.com/",
    "all_locations": "Los Angeles, CA, USA",
    "long_description": "",
    "one_liner": "We create automation technology for the cannabis industry.",
    "team_size": 12,
    "industry": "B2B",
    "subindustry": "B2B -> Supply Chain and Logistics",
    "launched_at": 1541124183,
    "tags": [
      "Robotic Process Automation",
      "Robotics",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2019",
    "status": "Active",
    "industries": [
      "B2B",
      "Supply Chain and Logistics"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/sorting-robotics",
    "api": "https://yc-oss.github.io/api/batches/winter-2019/sorting-robotics.json"
  },
  {
    "id": 12080,
    "name": "Aura Vision",
    "slug": "aura-vision",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/06dd0022a30071b010e7c41ab3e012079397a6d2.png",
    "website": "https://auravision.ai",
    "all_locations": "London, England, United Kingdom",
    "long_description": "Aura Vision is like Google Analytics for physical stores. We help retailers make more sales by using their existing security cameras and our plug & play AI to better measure their customers and stores.",
    "one_liner": "Visitor analytics for physical retail stores using existing security…",
    "team_size": 10,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1541648089,
    "tags": [
      "SaaS",
      "IoT",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2019",
    "status": "Active",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United Kingdom",
      "Europe",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/aura-vision",
    "api": "https://yc-oss.github.io/api/batches/winter-2019/aura-vision.json"
  },
  {
    "id": 12271,
    "name": "Allure Systems",
    "slug": "allure-systems",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/876f66dff22e97cba80fe969792f2c63dd568d79.png",
    "website": "http://www.alluresystems.com/",
    "all_locations": "New York, NY, USA",
    "long_description": "Allure Systems was Acquired by Farfetch (NASDAQ: FTCH) in Dec 2021. AllureSystems uses generative A.I. to create stunning apparel images for eCommerce. Allure works with leading fashion retailers to improve conversion rates by creating images that resonate with their clients in a scalable and cost-effective way. \r\nWith a single photo of clothing,  a brand can produce unlimited images, on any model, instantly.  The ability to show styles on models in every size increases conversion rates and wow the customers. Without needing models or photographers on-site, brands can produce images for their product page at scale.\r\n",
    "one_liner": "A.I. to create stunning fashion images for eCommerce. ",
    "team_size": 18,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1544065373,
    "tags": [
      "Generative AI",
      "Computer Vision",
      "E-commerce",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2019",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/allure-systems",
    "api": "https://yc-oss.github.io/api/batches/winter-2019/allure-systems.json"
  },
  {
    "id": 12846,
    "name": "Traces",
    "slug": "traces",
    "former_names": [
      "EllipseAI"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/95c9d28f031050f88288e5b80195b4ca69c2dd41.png",
    "website": "https://www.traces.ai",
    "all_locations": "Mountain View, CA, USA",
    "long_description": "We analyze thousands of video streams to find and track people without facial recognition. \r\nOur tech is available as an API and has multiple use cases. Unique people counting, forensic people search, falsa alarm filtering and many more. \r\n",
    "one_liner": "Transform your video monitoring with AI",
    "team_size": 10,
    "industry": "B2B",
    "subindustry": "B2B -> Security",
    "launched_at": 1559260859,
    "tags": [
      "Artificial Intelligence",
      "Deep Learning",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2019",
    "status": "Active",
    "industries": [
      "B2B",
      "Security"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/traces",
    "api": "https://yc-oss.github.io/api/batches/summer-2019/traces.json"
  },
  {
    "id": 13109,
    "name": "Taiv",
    "slug": "taiv",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/517858a2f6d1535b89d71bd9bf5a0f334c3c7f8d.png",
    "website": "https://taiv.tv",
    "all_locations": "Winnipeg, MB, Canada",
    "long_description": "Taiv puts TVs on autopilot, automatically switching between cable, our own streaming channels, digital signage, and trivia.  Our proprietary AI model analyzes the live video feed and intelligently switches sources during commercial breaks, show changes, or based on the time of day, to show the best possible content & ads for any environment.\r\n\r\nWe offer this for free to venues and make money by selling ads, which we rev-share back with the venue, turning their TVs from a cost center to a profit center. ",
    "one_liner": "Taiv uses AI to make businesses TVs more entertaining & valuable.",
    "team_size": 40,
    "industry": "B2B",
    "subindustry": "B2B -> Marketing",
    "launched_at": 1584223249,
    "tags": [
      "Marketplace",
      "Computer Vision",
      "B2B",
      "Advertising",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2020",
    "status": "Active",
    "industries": [
      "B2B",
      "Marketing"
    ],
    "regions": [
      "Canada",
      "America / Canada"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/taiv",
    "api": "https://yc-oss.github.io/api/batches/winter-2020/taiv.json"
  },
  {
    "id": 13307,
    "name": "Photoroom",
    "slug": "photoroom",
    "former_names": [
      "Artizans",
      "PhotoRoom"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/e5f5e5ed0c922fb566fac15578940996a8f6a930.png",
    "website": "https://photoroom.com/",
    "all_locations": "Paris, Île-de-France, France",
    "long_description": "Photoroom provides photo editing software powerful enough to create outstanding images yet simple enough to be used without any training. We leverage deep learning to translate pixels into objects, drastically simplifying non-creative tasks such as removing backgrounds from images.\r\n\r\nOur mission: enable entrepreneurs and small businesses to compose images that stand out.",
    "one_liner": "Power commerce photography with generative AI",
    "team_size": 100,
    "industry": "Consumer",
    "subindustry": "Consumer -> Content",
    "launched_at": 1596474431,
    "tags": [
      "Generative AI",
      "Computer Vision",
      "Design Tools",
      "API",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2020",
    "status": "Active",
    "industries": [
      "Consumer",
      "Content"
    ],
    "regions": [
      "France",
      "Europe",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/photoroom",
    "api": "https://yc-oss.github.io/api/batches/summer-2020/photoroom.json"
  },
  {
    "id": 13472,
    "name": "Oda",
    "slug": "oda",
    "former_names": [
      "Zappeal",
      "Oda",
      "Oda (was Zappeal)"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b282b3863a1e15b0e08e9b79cf5ac972840f5523.png",
    "website": "https://www.odastudio.ai/?ref=yc",
    "all_locations": "Los Angeles, CA, USA; Remote",
    "long_description": "Oda is an AI agent for home design. Homebuyers and renters alike can use Oda to discover their interior design preferences, apply those preferences to their new home, and then find the best furniture, décor, and appliances aggregated from many different online retailers. Oda distributes its product to homebuyers and renters through partnerships with real estate companies and platforms. Real estate partners add Oda AI iFrames to their websites to showcase listed homes with AI-generated designs. Each AI iFrame is directly linked to an Oda board, allowing consumers to transition from an iFrame to Oda to further personalize the designs and create their dream home.",
    "one_liner": "AI Agent for Home Design",
    "team_size": 9,
    "industry": "B2B",
    "subindustry": "B2B -> Marketing",
    "launched_at": 1584035955,
    "tags": [
      "Machine Learning",
      "Computer Vision",
      "E-commerce",
      "AI Assistant"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2020",
    "status": "Active",
    "industries": [
      "B2B",
      "Marketing"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/oda",
    "api": "https://yc-oss.github.io/api/batches/winter-2020/oda.json"
  },
  {
    "id": 21769,
    "name": "Roboflow",
    "slug": "roboflow",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/ba0036069bd338a4c6188cb137722d8f584d0016.png",
    "website": "https://roboflow.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Roboflow enables developers to make the world programmable.\r\n\r\nUse our tools to build better datasets (collect image, video / annotate), models (foundation and fine tuned small models), and deployments (self hosted, edge, APIs, SDKs) for computer vision. Over 250k developers, including those from over half the Fortune 100, build with our open source and hosted tools.\r\n\r\nBuild with us: https://app.roboflow.com\r\nHack with us: https://roboflow.slab.com/public/posts/roboflow-hackathons-external-u478m1iz\r\nWork with us: roboflow.com/careers\r\n",
    "one_liner": "🖼️ Give your software the sense of sight.",
    "team_size": 100,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1598130074,
    "tags": [
      "Artificial Intelligence",
      "Developer Tools",
      "Machine Learning",
      "Computer Vision",
      "Enterprise"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2020",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/roboflow",
    "api": "https://yc-oss.github.io/api/batches/summer-2020/roboflow.json"
  },
  {
    "id": 21811,
    "name": "Hypermile",
    "slug": "hypermile",
    "former_names": [
      "Creation Labs"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b25c7b5a70e0fab68abb8837d04d772f89ba6623.png",
    "website": "https://hypermile.ai",
    "all_locations": "London, England, United Kingdom",
    "long_description": "Hypermile is on a mission to improve trucking efficiency, sustainability and safety by developing an AI driver assistance system 🚛 🌎🌱.\r\n\r\nToday, fuel is the main cost component for logistics operators, accounting for >1/3 of all operating costs. Driving behavior is a key factor affecting overall fuel consumption and can increase fuel use by up to 35%. However, current solutions are not cost effective, so logistics operators are constantly looking for new solutions. \r\n\r\nIn addition, logistics operators are under huge sustainability pressure, as Heavy Goods Vehicles (HGVs) are responsible for 16% of the UK's transport emissions but only 5% of the miles travelled. While electric vehicle sales for passenger vehicles are on the rise, the same can't be said for long-haul HGVs due to high initial cost and limited range, making it impractical for logistic purposes. \r\n\r\nWith this problem in mind, we aim to leverage the latest AI techniques to improve the fuel efficiency of diesel trucks today, and increase the range of zero-emission trucks of the future. \r\n\r\nOur product Hypermile Co-Pilot is a retrofittable AI cruise control for commercial vehicles focused on controlling the speed of the truck efficiently. We have trained the AI algorithms to learn the best techniques for saving fuel: anticipating how traffic flow will change, optimising speed based on the road gradient and maximizing vehicle coasting. As a result, we can reduce diesel consumption by 11% and extend the range of battery-electric vehicles by 15%. The long term vision is to incrementally build higher levels of autonomy with the next milestone being a Level-3 autonomous trucking solution. \r\n\r\nThe company was founded in May 2020 and raised a $1.5M pre-seed round in May 2021 from Y Combinator, Greg Brockman (CTO of OpenAI), Luc Vincent (former Executive VP of Autonomous Driving at Lyft Level 5) and others. We’ve received a number of R&D grants from Innovate UK, Department for Transport and Horizons 2020. We’re currently a team of 10 across Commercial, Product and Engineering (including 4. sub-teams cloud software, machine learning, automotive software and electronics).\r\n",
    "one_liner": "Driver co-pilot to make trucking more efficient",
    "team_size": 11,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1615568678,
    "tags": [
      "Autonomous Trucking",
      "Computer Vision",
      "Logistics",
      "Climate"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2020",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United Kingdom",
      "Europe",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/hypermile",
    "api": "https://yc-oss.github.io/api/batches/summer-2020/hypermile.json"
  },
  {
    "id": 21962,
    "name": "Hellometer",
    "slug": "hellometer",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/a6ce1063846053edd4d35f8feec4badb3dc82dd8.png",
    "website": "https://hellometer.io/",
    "all_locations": "Los Angeles, CA, USA",
    "long_description": "Hellometer helps fast food owners' grow same store sales using security cameras to improve customer wait times.\r\n\r\nSpeed of service is fast food's core value proposition (it’s literally in the name) and owners currently don't have a reliable way to measure it. We show them when and where they have slowdowns and for every 7s they improve service times, owners see 1% increase in revenue. ",
    "one_liner": "Making fast food faster",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1598120897,
    "tags": [
      "SaaS",
      "Computer Vision",
      "B2B"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2020",
    "status": "Active",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/hellometer",
    "api": "https://yc-oss.github.io/api/batches/summer-2020/hellometer.json"
  },
  {
    "id": 22664,
    "name": "SBX Robotics",
    "slug": "sbx-robotics",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/511a67e1066575bd8304628248a6a9307430e18f.png",
    "website": "https://www.sbxrobotics.com/",
    "all_locations": "Toronto, ON, Canada",
    "long_description": "SBX Robotics generates synthetic data that teaches robots to see. We use simulation software to create training data 10x faster and cheaper than annotation services or in-house teams. \r\n\r\nInstead of being blocked on data, our clients send 25 images from their robot’s camera, and receive 25,000 perfectly labeled synthetic training images. SBX data is ready to be used by deep learning computer vision models. ",
    "one_liner": "Synthetic data for better vision.",
    "team_size": 5,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1616603536,
    "tags": [
      "Artificial Intelligence",
      "Machine Learning",
      "Robotics",
      "Computer Vision",
      "Data Engineering"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2021",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "Canada",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/sbx-robotics",
    "api": "https://yc-oss.github.io/api/batches/winter-2021/sbx-robotics.json"
  },
  {
    "id": 22743,
    "name": "Segments.ai",
    "slug": "segments-ai",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/ac88c08aefaf0753bc9d29d8d7ced656148b852c.png",
    "website": "https://segments.ai",
    "all_locations": "Brussels, Brussels, Belgium; Remote",
    "long_description": "[Segments.ai](http://segments.ai/) is helping robotics and automotive companies label their multi-sensor data for AI training and validation. Our platform enables customers to efficiently annotate their point cloud and image data, accelerating their path to autonomy.\r\n\r\nWe're a fast-growing, remote-first YC startup with a lean team and healthy runway. [Segments.ai](http://segments.ai/) is used by large organizations as well as innovative startups building the next generation of autonomous drones, delivery robots, self-driving cars, and more.",
    "one_liner": "Build better computer vision models by building better datasets",
    "team_size": 8,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1615300374,
    "tags": [
      "Deep Learning",
      "Developer Tools",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2021",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "Belgium",
      "Europe",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/segments-ai",
    "api": "https://yc-oss.github.io/api/batches/winter-2021/segments-ai.json"
  },
  {
    "id": 22744,
    "name": "Encord",
    "slug": "encord",
    "former_names": [
      "Cord Technologies",
      "Cord"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b0c0b8150edc64332f4d529343a9096db99002e1.png",
    "website": "https://encord.com",
    "all_locations": "London, England, United Kingdom",
    "long_description": "Encord is the leading data platform for AI. We help top AI teams get models into production faster with human-in-the-loop workflows for labeling and RLHF, infrastructure for data-centric model testing, and powerful data curation and management.",
    "one_liner": "Building the data backbone for the (artificial) intelligence…",
    "team_size": 100,
    "industry": "B2B",
    "subindustry": "B2B -> Infrastructure",
    "launched_at": 1613768381,
    "tags": [
      "Artificial Intelligence",
      "Developer Tools",
      "Machine Learning",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2021",
    "status": "Active",
    "industries": [
      "B2B",
      "Infrastructure"
    ],
    "regions": [
      "United Kingdom",
      "Europe"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/encord",
    "api": "https://yc-oss.github.io/api/batches/winter-2021/encord.json"
  },
  {
    "id": 22752,
    "name": "ClipDrop",
    "slug": "clipdrop",
    "former_names": [
      "Init ML",
      "Clickdrop"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/3bfd4a654412f2405d3448ad846ed61f08074a04.png",
    "website": "https://clipdrop.co",
    "all_locations": "Paris, Île-de-France, France; Remote",
    "long_description": "ClipDrop is an app that turns regular mobile photos into professional product visuals.\r\n\r\nThanks to companies like Poshmark, Etsy and Ebay, there are now over 25M sellers who need great visuals for their shops but most of them don’t have access to a professional photographer or a design team. We replace all of this with our app available on mobile and desktop.\r\n\r\nWe’re a team of former Google, Facebook employees and Machine learning PhD’s and academic Professors. We believe that machine learning will bring professional photography and design to millions of businesses for a fraction of the cost.",
    "one_liner": "Turn regular mobile photos into professional product visuals",
    "team_size": 5,
    "industry": "Consumer",
    "subindustry": "Consumer -> Content",
    "launched_at": 1614841884,
    "tags": [
      "SaaS",
      "Computer Vision",
      "Design Tools"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2021",
    "status": "Acquired",
    "industries": [
      "Consumer",
      "Content"
    ],
    "regions": [
      "France",
      "Europe",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/clipdrop",
    "api": "https://yc-oss.github.io/api/batches/winter-2021/clipdrop.json"
  },
  {
    "id": 22969,
    "name": "LightTwist",
    "slug": "lighttwist",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/69063ba25c16af04c5fdb92fd680138cd0eaea3b.png",
    "website": "https://lighttwist.com",
    "all_locations": "Boulder, CO, USA; Remote",
    "long_description": "LightTwist is your virtual studio in the cloud. Record and stream video in a customizable virtual studio that you control from your browser.",
    "one_liner": "Record video in a photorealistic virtual studio all from your browser",
    "team_size": 4,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1616254222,
    "tags": [
      "Augmented Reality",
      "Computer Vision",
      "Design Tools"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2021",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/lighttwist",
    "api": "https://yc-oss.github.io/api/batches/winter-2021/lighttwist.json"
  },
  {
    "id": 23451,
    "name": "MarqVision",
    "slug": "marqvision",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b993f487d88442acd03e44f8b8ba2ff9dd1c72c7.png",
    "website": "https://www.marqvision.com/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "MarqVision’s mission is to protect and build a future shaped by original ideas, innovations, and creativity. As a leading online brand protection solution, we help global brands identify and remove counterfeits and combat piracy from over 1,500 platforms and thousands of rogue websites in over 118 countries. In a time when counterfeiting poses an increasingly serious challenge, we believe that democratizing legal expertise and access to the latest in generative AI technology is critical for continuing to support the inventors, developers, and artists of the world who work tirelessly to deliver safe, high-quality products.\r\n\r\nMarqVision’s technology powers everything from detection, monitoring, and even enforcement to protect brands at scale. Founded in 2020 by Harvard Law graduates, MarqVision is proudly backed by Altos Ventures, DST Global Partners, Softbank, Atinum Investments and Y Combinator. Our commitment to innovation has also been recognized with a prestigious 2022 Innovation Award from LVMH Louis Vuitton Moët Hennessy (LVMH), and we are honored to be part of the LVMH accelerator program, La Maison des Startups, at the Station F incubator. As we bring forth the next evolution of brand protection, we invite businesses everywhere to join us in safeguarding the creativity that drives our world.",
    "one_liner": "IP operating software for brands and content companies",
    "team_size": 200,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1624608504,
    "tags": [
      "Artificial Intelligence",
      "SaaS",
      "Computer Vision",
      "B2B",
      "LegalTech"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2021",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": true,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/marqvision",
    "api": "https://yc-oss.github.io/api/batches/summer-2021/marqvision.json"
  },
  {
    "id": 24142,
    "name": "SnapCalorie",
    "slug": "snapcalorie",
    "former_names": [
      "CalorieSnap"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/8fb8d3ff1ae8ec164dd664632cc42c03b043c549.png",
    "website": "https://www.snapcalorie.com/",
    "all_locations": "New York, NY, USA; Washington, DC, USA",
    "long_description": "SnapCalorie is the world’s first app where you can take a photo of ANY meal and get an accurate calorie count.  It takes seconds to use and is more accurate than a trained nutritionist. The team previously co-founded Google Lens, Cloud Vision API, and published a CVPR paper demonstrating the first algorithm to outperform a professional nutritionist at calorie counting.",
    "one_liner": "Single photo nutrition tracking.",
    "team_size": 5,
    "industry": "Consumer",
    "subindustry": "Consumer",
    "launched_at": 1627329794,
    "tags": [
      "Computer Vision",
      "Fitness",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2021",
    "status": "Active",
    "industries": [
      "Consumer"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/snapcalorie",
    "api": "https://yc-oss.github.io/api/batches/summer-2021/snapcalorie.json"
  },
  {
    "id": 24383,
    "name": "Milky Way AI",
    "slug": "milky-way-ai",
    "former_names": [
      "Milky Way AI Pte.Ltd"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/2efe7f33198c252ca563c3f685bd5e290b4064d2.png",
    "website": "https://milkyway.ai/",
    "all_locations": "Singapore, Singapore; Remote",
    "long_description": "We help CPG brands to understand how their products are being displayed, priced and what are their competitors are doing across millions of physical stores in real time with our computer vision powered mobile app. \r\n\r\nEach year these brands spend $500 bn annually buying prime retail shelf space to influence customer purchasing decisions, but they have no easy way to audit it. \r\n\r\nOur mobile app reduces the time of these audits by 10x and cost by 3x.",
    "one_liner": "Mobile app for CPG brands to connect to millions of stores globally",
    "team_size": 5,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1624944246,
    "tags": [
      "Artificial Intelligence",
      "SaaS",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2021",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "Singapore",
      "Southeast Asia",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/milky-way-ai",
    "api": "https://yc-oss.github.io/api/batches/summer-2021/milky-way-ai.json"
  },
  {
    "id": 24551,
    "name": "Mach9",
    "slug": "mach9",
    "former_names": [
      "Mach9 Robotics"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/232339d6edde0605ea880f4aaef47c45acf14848.png",
    "website": "https://www.mach9.ai/",
    "all_locations": "San Francisco, CA, USA; Pittsburgh, PA, USA",
    "long_description": "Mach9 is at the forefront of leveraging advanced machine learning and computer vision techniques to transform geospatial data into actionable insights for urban development and infrastructure management. Our cutting-edge technology automates the detection and analysis of key urban features, aiding in the planning and maintenance of transportation networks.",
    "one_liner": "The Fastest Tool for Automating Geospatial Production",
    "team_size": 15,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1628526474,
    "tags": [
      "Machine Learning",
      "Computer Vision",
      "Infrastructure",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2021",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/mach9",
    "api": "https://yc-oss.github.io/api/batches/summer-2021/mach9.json"
  },
  {
    "id": 24567,
    "name": "Tenyks",
    "slug": "tenyks",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/7006298209ca0e4b566665242aadbc44f58b1d59.png",
    "website": "http://tenyks.ai/",
    "all_locations": "Cambridge, England, United Kingdom; Remote",
    "long_description": "Tenyks (YC S21) is a Cambridge University spin-out building the World's Most Versatile Visual Intelligence Platform—think Snowflake for Vision or GPT for Video.\r\n\r\nProblem: Companies today collect oceans of visual data (from cameras, drones, and satellites), but struggle to extract actionable insights. Current solutions rely heavily on manual analysis by call centres in locations like the Philippines or AI platforms narrowly focused on security rather than deeper operational insights. This leaves critical improvements in efficiency, customer satisfaction, and revenue growth unrealised.\r\n\r\nSolution: Tenyks unlocks unprecedented insights by applying advanced multimodal Vision-Language Models (VLMs) capable of comprehensive video summarisation, retrieval, and visual question-answering. These VLMs are seamlessly combined with specialised analytics for emotion detection, activity recognition, object tracking, and even gait analysis. Our platform transforms ordinary visual footage into extraordinary operational intelligence.\r\n\r\nInitial Focus: Starting with Quick Service Restaurants (QSRs), we enable operations leaders to instantly understand customer flow, kitchen efficiency, staff productivity, and quality of service using their existing security camera footage—turning previously inaccessible data into direct operational improvements and clear financial ROI. For instance, insights from Tenyks can accelerate the speed of service significantly; even a 1-second improvement in service speed could generate $30,000 additional annual revenue per restaurant. For a multi-unit owner of 100 restaurants, that's an additional $3 million per year.\r\n\r\nTraction: We've recently secured our first Fortune 500 customer, joining other major enterprises, global system integrators, and high-growth startups trusting Tenyks for powerful, data-driven decision-making.\r\n\r\nWhy Tenyks: Our patented technology originates from the founders' PhD research at Cambridge University. Previously, we helped world-leading teams scale high-performing Vision AI in production. \r\n\r\nRecognition: Recognised as a Rising Star in Gen AI by Sifted, Best Product of the Year by Vision AI Alliance, and Company of the Year by Cambridge University (previously awarded to DeepMind).",
    "one_liner": "The World's Most Versatile Video Answering Engine ",
    "team_size": 11,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1630087785,
    "tags": [
      "Artificial Intelligence",
      "Computer Vision",
      "Video",
      "AI",
      "AI Assistant"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2021",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United Kingdom",
      "Europe",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/tenyks",
    "api": "https://yc-oss.github.io/api/batches/summer-2021/tenyks.json"
  },
  {
    "id": 26254,
    "name": "Eventual",
    "slug": "eventual",
    "former_names": [
      "Eventual Computing"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/f429c16ee024d738c1b758e7c2d0ca5d811f204b.png",
    "website": "https://www.daft.ai/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Every breakthrough AI application, from foundation models to autonomous vehicles, relies on processing massive volumes of images, video, and complex data. But today’s data platforms (like Databricks and Snowflake) are built on top of tools made for spreadsheet-like analytics, not the petabytes of multimodal data that power AI. As a result, teams waste months on brittle infrastructure instead of conducting research and building their core product.\r\n\r\nEventual was founded in 2022 to solve this. Our mission is to make querying any kind of data, images, video, audio, text, as intuitive as working with tables, and powerful enough to scale to production workloads. Our open-source engine, Daft, is purpose-built for real-world AI systems: coordinating with external APIs, managing GPU clusters, and handling failures that traditional engines can’t. Daft already powers critical workloads at companies like Amazon, Mobileye, Together AI, and CloudKitchens.\r\n\r\nWe’ve assembled a world-class team from Databricks, AWS, Nvidia, Pinecone, GitHub Copilot, Tesla, and more, quadrupling our size within a year. With backing from Y Combinator, Caffeinated Capital, Array.vc, and top angels from the co-founders of Databricks and Perplexity, we’re looking to double the team now. Join us—Eventual is just getting started.\r\n\r\nPlease note we are looking for someone who is willing and able to come into our San Francisco office in the Mission district 4 days / week.",
    "one_liner": "Building the AI data engine for any modality and scale",
    "team_size": 18,
    "industry": "B2B",
    "subindustry": "B2B -> Infrastructure",
    "launched_at": 1648154182,
    "tags": [
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2022",
    "status": "Active",
    "industries": [
      "B2B",
      "Infrastructure"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/eventual",
    "api": "https://yc-oss.github.io/api/batches/winter-2022/eventual.json"
  },
  {
    "id": 26718,
    "name": "Cerrion",
    "slug": "cerrion",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/a2cfaa4757206398a9d1678a216905dc2a248f11.png",
    "website": "https://www.cerrion.com/",
    "all_locations": "Zürich, ZH, Switzerland",
    "long_description": "Cerrion helps manufacturers automatically detect, understand and eliminate problems on their production lines using video-based Computer Vision. Our AI leverages standard CCTV cameras and learns how a manufacturing process looks like when things are going well and can automatically detect and track problems in real-time.\r\n\r\nFor example, one of our customers, a Pepsi supplier producing 500 bottles per minute now automatically detects and reacts to a fallen bottle before it starts blocking their production line. ",
    "one_liner": "Video AI to automatically detect and respond to production line…",
    "team_size": 16,
    "industry": "Industrials",
    "subindustry": "Industrials",
    "launched_at": 1659519771,
    "tags": [
      "Artificial Intelligence",
      "Deep Learning",
      "Computer Vision",
      "Video",
      "Manufacturing"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2022",
    "status": "Active",
    "industries": [
      "Industrials"
    ],
    "regions": [
      "Switzerland",
      "Europe"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/cerrion",
    "api": "https://yc-oss.github.io/api/batches/summer-2022/cerrion.json"
  },
  {
    "id": 26802,
    "name": "Apply Design",
    "slug": "apply-design",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/731fd6f22634f935a03484945b5b569dae8c8ed9.png",
    "website": "http://www.applydesign.io",
    "all_locations": "Tel Aviv-Yafo, Tel Aviv District, Israel",
    "long_description": "Apply Design is a leading AI-powered virtual staging app that empowers real estate professionals to showcase the full potential of their properties to prospective buyers, helping them sell homes faster and for higher prices. \r\n\r\nWe virtually stage over 10,000 properties monthly, transforming images of vacant or outdated spaces into fully furnished, captivating property photos. Our proprietary AI-powered software is the only solution capable of generating photorealistic designs in one click while also enabling instant customization of any detail with complete control.\r\n\r\nThis is a $10B market opportunity, given the 50M properties sold or rented annually in North America and Europe alone. ",
    "one_liner": "Helping realtors showcase the full potential of their properties",
    "team_size": 4,
    "industry": "Real Estate and Construction",
    "subindustry": "Real Estate and Construction",
    "launched_at": 1655775419,
    "tags": [
      "Generative AI",
      "SaaS",
      "Computer Vision",
      "Proptech",
      "E-commerce"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2022",
    "status": "Active",
    "industries": [
      "Real Estate and Construction"
    ],
    "regions": [
      "Israel",
      "Middle East and North Africa",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/apply-design",
    "api": "https://yc-oss.github.io/api/batches/summer-2022/apply-design.json"
  },
  {
    "id": 27221,
    "name": "CAPSULE",
    "slug": "capsule",
    "former_names": [
      "Dryftwell",
      "GLIMPSE"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/19f195e9a25d1cff1f914f65ceb3e7458c6d52b9.png",
    "website": "https://www.shopcapsule.ai/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "CAPSULE is a mobile app that makes it easy to save and buy the things you find on any social media platform. Just snap a screenshot of anything you like, from any platform, and we search the entire internet to instantly give you shoppable links. \r\n\r\nInstead of searching hundreds of websites and sifting through thousands of products on your own, CAPSULE lets you find inspiration from anywhere and uses advanced machine learning to return results that feel like magic. ",
    "one_liner": "Buy anything you find on social media",
    "team_size": 4,
    "industry": "Consumer",
    "subindustry": "Consumer -> Apparel and Cosmetics",
    "launched_at": 1661989948,
    "tags": [
      "Artificial Intelligence",
      "Generative AI",
      "Machine Learning",
      "Computer Vision",
      "E-commerce"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2022",
    "status": "Inactive",
    "industries": [
      "Consumer",
      "Apparel and Cosmetics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/capsule",
    "api": "https://yc-oss.github.io/api/batches/summer-2022/capsule.json"
  },
  {
    "id": 27828,
    "name": "Scanbase",
    "slug": "scanbase",
    "former_names": [
      "Scanbase",
      "Inc."
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/2982f68c8c82ccb0dcb8909ae50c7cdbbdcd9b70.png",
    "website": "https://www.scanbase.com",
    "all_locations": "Los Angeles, CA, USA",
    "long_description": "Scanbase makes it easy for medical companies to convert photos of rapid diagnostic tests into results. We do this by providing a simple API that any medical company can access.\r\n",
    "one_liner": "The API for Diagnostic Test Analysis (COVID-19, FLU, RSV, STD,…",
    "team_size": 10,
    "industry": "Healthcare",
    "subindustry": "Healthcare -> Diagnostics",
    "launched_at": 1670991822,
    "tags": [
      "Artificial Intelligence",
      "Machine Learning",
      "Computer Vision",
      "Health Tech",
      "Telemedicine"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2023",
    "status": "Active",
    "industries": [
      "Healthcare",
      "Diagnostics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/scanbase",
    "api": "https://yc-oss.github.io/api/batches/winter-2023/scanbase.json"
  },
  {
    "id": 27860,
    "name": "Dream3D",
    "slug": "dream3d",
    "former_names": [
      "MettaSpace"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/dc5c128914787f1ad09c34983b9c40c1200da598.png",
    "website": "https://dream3d.com",
    "all_locations": "New York, NY, USA",
    "long_description": "Dream3D builds generative models to simulate and emulate worlds, real and imagined.",
    "one_liner": "Generative AI Worlds",
    "team_size": 3,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1677865645,
    "tags": [
      "Generative AI",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2023",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/dream3d",
    "api": "https://yc-oss.github.io/api/batches/winter-2023/dream3d.json"
  },
  {
    "id": 28114,
    "name": "rex.fit",
    "slug": "rex-fit",
    "former_names": [
      "Babylon AI",
      "BabylonAI",
      "Rex"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/c618208d2cb852eeff16409fb7e787701c395b91.png",
    "website": "https://www.rex.fit",
    "all_locations": "Zürich, ZH, Switzerland",
    "long_description": "The DROP by Rex.Fit is an AI wearable camera that automates nutrition tracking using computer vision. It has garnered more than 93k USD in preorders (~450 units) since its launch last month. The nutrition estimation and recommendation tech behind the DROP is already integrated as an API for fitness chains, generating hundreds of thousands of dollars in yearly revenue for them. The DROP is built by brothers, sports nutritionists and computer vision engineers from the Swiss Federal Institute of Technology (ETH Zurich).",
    "one_liner": "Automating nutrition tracking.",
    "team_size": 2,
    "industry": "Consumer",
    "subindustry": "Consumer",
    "launched_at": 1674733041,
    "tags": [
      "Artificial Intelligence",
      "Hard Tech",
      "Computer Vision",
      "Consumer Health Services",
      "Fitness"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2023",
    "status": "Active",
    "industries": [
      "Consumer"
    ],
    "regions": [
      "Switzerland",
      "Europe"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/rex-fit",
    "api": "https://yc-oss.github.io/api/batches/winter-2023/rex-fit.json"
  },
  {
    "id": 28859,
    "name": "MICSI",
    "slug": "micsi",
    "former_names": [
      "MICSI (Microstructure Imaging, Inc)"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/29d35560d45b90c5227b12877556942576e43627.png",
    "website": "https://www.micsi.co/",
    "all_locations": "New York, NY, USA",
    "long_description": "MICSI is introducing AI software that doubles resolution and halves scan time. This breakthrough enables imaging centers to significantly enhance their capacity and patient throughput, potentially saving countless lives and generating an additional $2 million of revenue per MRI scanner. Our initial offering serves as a stepping stone toward the company’s larger vision of transforming the MRI into a truly quantitative instrument that is capable of providing highly reproducible data for more accurate diagnoses and patient management. ",
    "one_liner": "Higher resolution MRI with faster scan times.",
    "team_size": 2,
    "industry": "Healthcare",
    "subindustry": "Healthcare -> Diagnostics",
    "launched_at": 1687381964,
    "tags": [
      "Computer Vision",
      "Medical Devices",
      "Healthcare"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2023",
    "status": "Active",
    "industries": [
      "Healthcare",
      "Diagnostics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/micsi",
    "api": "https://yc-oss.github.io/api/batches/summer-2023/micsi.json"
  },
  {
    "id": 28867,
    "name": "Shasta Health",
    "slug": "shasta-health",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/d0ddbae01a1bda2827881248dc2c26ab87f27982.png",
    "website": "https://www.shasta.health",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Shasta Health builds AI agents to handle patient calls, verify insurance and automate admin tasks for healthcare clinics",
    "one_liner": "AI calling & browser agents for healthcare",
    "team_size": 2,
    "industry": "Healthcare",
    "subindustry": "Healthcare -> Healthcare Services",
    "launched_at": 1690927737,
    "tags": [
      "Artificial Intelligence",
      "Generative AI",
      "Computer Vision",
      "Digital Health",
      "Healthcare"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2023",
    "status": "Active",
    "industries": [
      "Healthcare",
      "Healthcare Services"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/shasta-health",
    "api": "https://yc-oss.github.io/api/batches/summer-2023/shasta-health.json"
  },
  {
    "id": 28891,
    "name": "Cleancard",
    "slug": "cleancard",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b2b82979e8cd1a007de394d4f1a3a8e665968d02.png",
    "website": "https://www.cleancard.bio",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "We are combining synthetic biology and artificial intelligence to make cancer detection as easy as a pregnancy test. Cleancard's mission is to bring lab-grade diagnostics into the comfort of your home. Our novel method enables robust diagnostics and biomarker tracking from the urine. We are currently developing fully at-home, 30-minute tests for cancer using this methodology. We are constantly expanding the number of conditions we can detect from a single sample with our platform technology.",
    "one_liner": "Making cancer detection as easy as a pregnancy test",
    "team_size": 16,
    "industry": "Healthcare",
    "subindustry": "Healthcare -> Diagnostics",
    "launched_at": 1691571179,
    "tags": [
      "Artificial Intelligence",
      "Computer Vision",
      "Biotech",
      "Healthcare",
      "Diagnostics"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2023",
    "status": "Active",
    "industries": [
      "Healthcare",
      "Diagnostics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/cleancard",
    "api": "https://yc-oss.github.io/api/batches/summer-2023/cleancard.json"
  },
  {
    "id": 28959,
    "name": "sizeless",
    "slug": "sizeless",
    "former_names": [
      "sizeless GmbH"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/90ad40c9214ea17e0132605fba1e092c86e8b9a0.png",
    "website": "https://www.sizeless.co",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Make data-driven decisions. Optimize property management. With the property Digital Twin from sizeless, you can access highly accurate data to understand your property's details, make informed decisions on inspections, and work on the required management optimization measures.",
    "one_liner": "Instant 3D Digital Twins for Smarter Real Estate.",
    "team_size": 3,
    "industry": "Real Estate and Construction",
    "subindustry": "Real Estate and Construction",
    "launched_at": 1691128419,
    "tags": [
      "Artificial Intelligence",
      "Computer Vision",
      "Real Estate",
      "Construction",
      "Energy"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2023",
    "status": "Active",
    "industries": [
      "Real Estate and Construction"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/sizeless",
    "api": "https://yc-oss.github.io/api/batches/summer-2023/sizeless.json"
  },
  {
    "id": 29358,
    "name": "Aedilic",
    "slug": "aedilic",
    "former_names": [
      "speak&find"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/e453f612e8022f9284505dc7f70270165e918ea9.png",
    "website": "https://www.nonescape.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Open-source software for detecting AI-generated images (diffusion, GAN, deepfakes).",
    "one_liner": "Open-Source AI-generated image/deepfake detection",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Security",
    "launched_at": 1710792793,
    "tags": [
      "Artificial Intelligence",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2024",
    "status": "Active",
    "industries": [
      "B2B",
      "Security"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/aedilic",
    "api": "https://yc-oss.github.io/api/batches/winter-2024/aedilic.json"
  },
  {
    "id": 29396,
    "name": "EdgeTrace",
    "slug": "edgetrace",
    "former_names": [
      "EdgeTrace AI",
      "edgetrace"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/1a5e9f714f08ee19fe05c995f4d3940b758e86ef.png",
    "website": "https://edgetrace.ai",
    "all_locations": "",
    "long_description": "EdgeTrace unifies your entire camera network into a single, powerful intelligence platform–helping public safety teams detect threats faster, respond in real time, and protect the community.",
    "one_liner": "Describe It. Find It. Act On It.",
    "team_size": 4,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1710460608,
    "tags": [
      "GovTech",
      "Computer Vision",
      "B2B",
      "Video",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2024",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/edgetrace",
    "api": "https://yc-oss.github.io/api/batches/winter-2024/edgetrace.json"
  },
  {
    "id": 29442,
    "name": "Ocular AI",
    "slug": "ocular-ai",
    "former_names": [
      "AutoflowAI (Zapier for AI Copilots)",
      "AutoflowAI",
      "Ocular"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/2e20f659338993dfe61925632a05952fe44797ed.png",
    "website": "https://useocular.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Ocular AI is the data annotation engine for Generative AI, Computer Vision, and Enterprise AI models.\r\n\r\nWe help you transform unstructured, multi-modal data into golden datasets to power generative AI, frontier models, and computer vision.   \r\n\r\nOcular Foundry is the most intuitive, data-centric, and fastest platform that lets you label, annotate, version, and deploy your data for training models. It also orchestrates your annotation jobs, improving collaboration with members and annotators.   \r\n\r\nWith Ocular Bolt, shift from humans in the loop to experts in the loop to supercharge your data labeling and annotation projects. Our global expert workforce ensures fast, accurate results—no matter the scale or complexity of your data.  \r\n\r\nCompanies spend huge amounts on training data, but Foundry and Bolt are AI-native tools that lower costs, reduce manual effort, and accelerate high-quality data collection. We’re replacing outdated, clunky, and expensive data software!",
    "one_liner": "AI-Native Data Engine for LLMs, Computer Vision, & Enterprise AI",
    "team_size": 6,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1706216304,
    "tags": [
      "Artificial Intelligence",
      "Developer Tools",
      "Machine Learning",
      "Computer Vision",
      "Data Engineering"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2024",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/ocular-ai",
    "api": "https://yc-oss.github.io/api/batches/winter-2024/ocular-ai.json"
  },
  {
    "id": 29447,
    "name": "Deepnight",
    "slug": "deepnight",
    "former_names": [
      "DeepNight"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/419c6b136773af60713e2a4301554b4ef1bbd8a9.png",
    "website": "https://www.deepnight.ai/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "DeepNight is building the next generation of night vision with AI.",
    "one_liner": "Building The Next Generation of Night Vision Devices",
    "team_size": 12,
    "industry": "Industrials",
    "subindustry": "Industrials -> Defense",
    "launched_at": 1709629638,
    "tags": [
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2024",
    "status": "Active",
    "industries": [
      "Industrials",
      "Defense"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/deepnight",
    "api": "https://yc-oss.github.io/api/batches/winter-2024/deepnight.json"
  },
  {
    "id": 29503,
    "name": "Dragoneye",
    "slug": "dragoneye",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/354a00433e0332ff17869b4c08d6ee8d10b8a232.png",
    "website": "https://dragoneye.ai/",
    "all_locations": "New York, NY, USA",
    "long_description": "Dragoneye helps devs build their custom video detection models in less than 5 minutes. These models can then be used to power apps and features that use images and videos. No more arduous process of annotating any training data or doing any machine learning work themselves.\r\n\r\nTry out our demo today at https://playground.dragoneye.ai/ !",
    "one_liner": "Custom video detection models in less than 5 minutes",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1705986923,
    "tags": [
      "Developer Tools",
      "Computer Vision",
      "AI",
      "ML"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2024",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/dragoneye",
    "api": "https://yc-oss.github.io/api/batches/winter-2024/dragoneye.json"
  },
  {
    "id": 29635,
    "name": "DigitalCarbon",
    "slug": "digitalcarbon",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/5cd96189d0726eb13cddf2279ecddbb8f1d37895.png",
    "website": "https://www.digitalcarbon.ai",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Digitalcarbon transforms ordinary images and videos into interactive, photorealistic 3D environments. Our technology can take photos from any device and render 3D scenes at more than 100 frames per second on everyday devices. \r\n\r\nThe founders were the first and second hires at a previous YC company AssemblyAI, and have more than 8 years of experience building AI models. \r\n\r\nCreating immersive 3D experiences typically requires complex equipment and suffers from slow rendering speeds. This has limited the adoption of 3D technology across various industries. Digitalcarbon fixes that, eliminating the need for specialized equipment and dramatically accelerating the rendering process.\r\n\r\nOur technology enables applications across various industries:\r\n* Real estate: Creating virtual property tours that feel remarkably lifelike\r\n* E-commerce: Providing interactive 3D product visualizations to boost consumer experience\r\n* Tourism: Helping tourist businesses attract more travelers with immersive virtual previews\r\n* Drone mapping and inspection: Enhancing aerial surveys and structural assessments with detailed 3D models\r\n\r\nThink Unreal Engine meets Matterport with no hardware, but faster, editable, and more accessible for businesses of all sizes.",
    "one_liner": "Transform Images And Videos Into Immersive 3D With AI",
    "team_size": 0,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1725300975,
    "tags": [
      "Computer Vision",
      "Real Estate",
      "B2B",
      "E-commerce",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2024",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/digitalcarbon",
    "api": "https://yc-oss.github.io/api/batches/summer-2024/digitalcarbon.json"
  },
  {
    "id": 29819,
    "name": "Weel",
    "slug": "weel",
    "former_names": [
      "Vizia"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/22dac63897681e1a31dc26b877ee786266ae0bff.png",
    "website": "https://weel.live/",
    "all_locations": "New York, NY, USA",
    "long_description": "Weel is the next-generation all-in-one driver co-pilot that redefines your driving experience by turning your smartphone into a complete safety and navigation hub. Our free app offers a built-in dashcam with easy video sharing, a smart navigation system, and advanced AI features—such as augmented reality navigation and ADAS—that reduce your risk by up to 30%. Say goodbye to expensive dashcams and complex setups – with Weel, you get complete driving safety and guidance in one free smartphone app.",
    "one_liner": "GPS & dashcam smartphone app",
    "team_size": 4,
    "industry": "Consumer",
    "subindustry": "Consumer -> Transportation Services",
    "launched_at": 1741795332,
    "tags": [
      "Augmented Reality",
      "Computer Vision",
      "Navigation",
      "Mobility",
      "Automotive"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2024",
    "status": "Active",
    "industries": [
      "Consumer",
      "Transportation Services"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/weel",
    "api": "https://yc-oss.github.io/api/batches/summer-2024/weel.json"
  },
  {
    "id": 29823,
    "name": "autarc",
    "slug": "autarc",
    "former_names": [
      "autarc GmbH"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/c6f422aa332e520cce9d631b8dfbcdfb14375c6e.png",
    "website": "https://www.autarc.energy/en",
    "all_locations": "Berlin, Berlin, Germany",
    "long_description": "With autarc we are building the OS for Europe's One-Stop Energy Installers.\r\n\r\nThe problem: Energy installers are eager to expand their deployment of heat pump and photovoltaic systems, yet they are constrained by inefficient sales, planning, and installation processes.\r\n\r\nThe solution: Our B2B software integrates CRM, planning, and design tools into a unified platform. This enables SMB installers to drastically cut down the pre-installation phase of home energy projects—from several weeks to just minutes. By leveraging LiDAR for spatial analysis, computer vision for automated assessment, and AI for system recommendations, we streamline the entire workflow. This results in a time reduction of up to 90%, enabling installers to confidently transition to and scale up sustainable home energy solutions.",
    "one_liner": "autarc is the OS for Europe's One-Stop Energy Installers",
    "team_size": 30,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1720714870,
    "tags": [
      "Lidar",
      "Computer Vision",
      "B2B",
      "Climate",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2024",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "Germany",
      "Europe",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/autarc",
    "api": "https://yc-oss.github.io/api/batches/summer-2024/autarc.json"
  },
  {
    "id": 29847,
    "name": "Bucket Robotics",
    "slug": "bucket-robotics",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/55cc697d9f14eca5a5d45772ac14d97a83df16ae.png",
    "website": "https://bucket.bot",
    "all_locations": "",
    "long_description": "Bucket Robotics builds deployable computer vision systems for manufacturing — without labeling, long pilots, or fragile rules.\r\nWe turn CAD and sample data into production-ready vision models that run on existing cameras and edge hardware. No manual labeling. No cold-start problem. Models deploy in minutes and adapt as parts, defects, and lines change.\r\n\r\nOur roots are in self-driving cars (Argo AI, Uber ATG, Stack AV), where we learned how to ship perception systems that operators trust in messy, real-world environments. We’re applying that playbook to factories: robust sensing, fast iteration, and tooling engineers actually enjoy using.\r\n\r\nManufacturers struggle with inspection because parts are too variable for rules-based vision and too expensive to inspect by hand. Legacy systems are rigid, hardware-locked, and slow to customize. We take the opposite approach: software-first vision that fits into existing automation and scales across SKUs, facilities, and workflows.\r\n\r\nAmerican Manufacturing is in the middle of a $700B automation push — but quality is still a trust problem. Bucket Robotics is building the vision infrastructure that lets factories automate inspection with confidence.",
    "one_liner": "Defect detection for manufacturing built from CAD and synthetic data.",
    "team_size": 4,
    "industry": "Industrials",
    "subindustry": "Industrials -> Manufacturing and Robotics",
    "launched_at": 1719001491,
    "tags": [
      "Robotic Process Automation",
      "Robotics",
      "Computer Vision",
      "Manufacturing"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2024",
    "status": "Active",
    "industries": [
      "Industrials",
      "Manufacturing and Robotics"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/bucket-robotics",
    "api": "https://yc-oss.github.io/api/batches/summer-2024/bucket-robotics.json"
  },
  {
    "id": 30251,
    "name": "Mecha Health",
    "slug": "mecha-health",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/e851087b2c25e5bd175d39d8631791d74e04ebb1.png",
    "website": "https://www.mecha-health.ai/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Mecha Health builds foundation models to automate x-ray analysis for radiologists. We take medical images and process them using proprietary models to produce accurate draft medical reports. Our first model was built in less than two months, and beat Microsoft, Google, and OpenAI on clinical accuracy metrics. On top of that, it’s two orders of magnitude smaller and trained with a quarter of the data.\r\n\r\nWe are partnering with the largest privately owned radiology practice in the US and a multinational tele-radiology company to provide them with their own foundation model, enabling their radiologists to go from reading 1 scan per hour to 1 scan every 5 minutes. By charging on a per scan basis, x-ray report generation represents a 40B+ market opportunity. ",
    "one_liner": "Foundation models to automate x-ray analysis for radiologists",
    "team_size": 4,
    "industry": "Healthcare",
    "subindustry": "Healthcare",
    "launched_at": 1737153298,
    "tags": [
      "Artificial Intelligence",
      "Machine Learning",
      "Computer Vision",
      "Health Tech",
      "Healthcare"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2025",
    "status": "Active",
    "industries": [
      "Healthcare"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/mecha-health",
    "api": "https://yc-oss.github.io/api/batches/winter-2025/mecha-health.json"
  },
  {
    "id": 30284,
    "name": "Exla",
    "slug": "exla",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/94cd00784e37842fc455ee2fd7b22d487b0693cf.png",
    "website": "https://exla.ai/",
    "all_locations": "",
    "long_description": "Exla aggressively quantizes AI models to minimize memory usage and maximize inference speed. Whether you're deploying LLMs, VLMs, VLAs, or custom models, Exla reduces memory footprint by up to 80% and accelerates inference by 3–20x - all with just a few lines of code.\r\n\r\nhttps://cal.com/exla-ai/schedule",
    "one_liner": "An SDK to run transformer models anywhere",
    "team_size": 0,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1740012412,
    "tags": [
      "Edge Computing Semiconductors",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/exla",
    "api": "https://yc-oss.github.io/api/batches/winter-2025/exla.json"
  },
  {
    "id": 30315,
    "name": "Optifye.ai",
    "slug": "optifye-ai",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/d86ffdce2296389239f29bc23023bc7867815208.png",
    "website": "https://www.optifye.ai",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Optifye.ai does AI performance monitoring for factory workers\r\n\r\nWe place cameras in factories and use vision AI to tell supervisors who's working and who's not in real time. \r\n\r\nThe shop floor has historically been a black box. With Optifye, manufacturing companies can now accurately measure worker output and boost efficiency!",
    "one_liner": "AI performance monitoring for factory workers",
    "team_size": 3,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1739567184,
    "tags": [
      "Hard Tech",
      "Computer Vision",
      "Manufacturing"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2025",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/optifye-ai",
    "api": "https://yc-oss.github.io/api/batches/winter-2025/optifye-ai.json"
  },
  {
    "id": 30317,
    "name": "Permitify",
    "slug": "permitify",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/e0fb1e449f45c8f9ca33c6947992cac6af3e8c0f.png",
    "website": "https://permitify.com",
    "all_locations": "",
    "long_description": "City building departments are understaffed and overworked. Meanwhile, builders lobby to remove power from building departments. Because building departments are usually the only profitable/self-sustaining branch of a local government, this is problematic. Permitify allows city build-plan reviewers to 10x their productivity covering the labor shortage, reducing the time required to issue a building permit, and allowing the city government's only profitable branch to stay intact.",
    "one_liner": "AI co-pilot for building plan review and building code compliance",
    "team_size": 2,
    "industry": "Real Estate and Construction",
    "subindustry": "Real Estate and Construction -> Construction",
    "launched_at": 1737593819,
    "tags": [
      "Generative AI",
      "GovTech",
      "Computer Vision",
      "Construction"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2025",
    "status": "Active",
    "industries": [
      "Real Estate and Construction",
      "Construction"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/permitify",
    "api": "https://yc-oss.github.io/api/batches/winter-2025/permitify.json"
  },
  {
    "id": 30446,
    "name": "Kirana AI",
    "slug": "kirana-ai",
    "former_names": [
      "Kirana"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/6bc9cf5c0f4cd5c6141c30f400757b42039051c6.png",
    "website": "https://www.kirana-ai.com",
    "all_locations": "New York, NY, USA",
    "long_description": "Kirana AI is building the first full-stack AI store manager.\r\n\r\nWith 100 years of family experience owning and operating grocery stores, we are starting there to prove our impact.\r\n\r\nOur first product utilizes an on-premise GPU that monitors the store 24/7, scans for theft, looks for workplace health and safety issues, and optimizes customer service. \r\n\r\nWith future POS/ordering data integrations, our manager will automate many of the day-to-day tasks of running a store, such as ordering, pricing, assortment, and delegating.",
    "one_liner": "AI manager for physical stores",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1747354989,
    "tags": [
      "Grocery",
      "Computer Vision",
      "Retail",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Spring 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/kirana-ai",
    "api": "https://yc-oss.github.io/api/batches/spring-2025/kirana-ai.json"
  },
  {
    "id": 30541,
    "name": "Code Four",
    "slug": "code-four",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/484fe167f81b504f3783e0d04f12060ec5bf7d11.png",
    "website": "https://codefour.us/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Code Four slashes the administrative burden on law enforcement through AI-driven automation. Officers spend up to a third of their shifts manually transcribing body camera footage, creating inaccuracies, reducing transparency, and cutting into frontline duties. We're here to eliminate these inefficiencies by integrating with body cameras, record management systems, and digital evidence management systems—acting as a software layer for data processing. \r\n\r\nWe free the most overworked and underappreciated people in the world: police officers.",
    "one_liner": "Modernizing the police workflow.",
    "team_size": 3,
    "industry": "Government",
    "subindustry": "Government",
    "launched_at": 1744335489,
    "tags": [
      "Artificial Intelligence",
      "GovTech",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Spring 2025",
    "status": "Active",
    "industries": [
      "Government"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/code-four",
    "api": "https://yc-oss.github.io/api/batches/spring-2025/code-four.json"
  },
  {
    "id": 30542,
    "name": "LineWise",
    "slug": "linewise",
    "former_names": [
      "Comply Genie",
      "Vision Nexus"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/52b288a75cbc24bbab29ace4752b6453e7db35bf.png",
    "website": "https://www.linewise.io/",
    "all_locations": "",
    "long_description": "LineWise is building an AI assistant for manufacturing teams to operate and resolve production issues, from defects to breakdowns. \r\n\r\nLineWise automatically extracts frontline know-how from live video recordings, turning them into structured SOPs and training guides. It also ingests generated SOPs, machine manuals, and past breakdown logs to suggest the most probable root causes when issues occur. \r\n\r\nOperators receive step-by-step guided troubleshooting, and as they confirm outcomes, LineWise learns from each resolution - converting every fix into a reusable playbook and proactively recommending preventive actions to cut future downtime.",
    "one_liner": "AI platform to train frontline workers to operate and fix issues",
    "team_size": 5,
    "industry": "B2B",
    "subindustry": "B2B -> Operations",
    "launched_at": 1743036496,
    "tags": [
      "Generative AI",
      "Computer Vision",
      "Manufacturing",
      "Operations"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Spring 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Operations"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/linewise",
    "api": "https://yc-oss.github.io/api/batches/spring-2025/linewise.json"
  },
  {
    "id": 30652,
    "name": "OnDeck AI",
    "slug": "ondeck-ai",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/9fb6ad4cbd4cdfac49ff1b40404d7053d5789883.png",
    "website": "https://www.ondeckai.com",
    "all_locations": "Vancouver, BC, Canada",
    "long_description": "OnDeck is the infrastructure layer that makes Vision Language Models accessible and scalable for enterprise. We let organizations instantly find any object, behavior or event, in any footage, without needing to train a model or collect any training data.\r\n\r\nThe Pain: Creating vision models usually takes months: collecting training data, training, then deployment.  Worse yet: \r\n+ it’s often impossible to get enough data for a specific task, and \r\n+ even the best cv models struggle to generalize across diverse camera setups, workflows and environments. \r\n\r\nTo overcome these blockers, we bet early on the power of VLMs and built a vision engine that can generalize across any task and doesn’t need any training data. We published a NeurIPS workshop paper showing our new methods with VLMs beat traditional CV even at niche tasks.\r\n\r\nOur current customers include:\r\n- National Defense Organizations\r\n- Robotics Research\r\n- Security cameras\r\n- Behaviour analysis for port monitoring\r\n- Off-shore oil & gas monitoring",
    "one_liner": "Analyze any footage, without training a model",
    "team_size": 5,
    "industry": "B2B",
    "subindustry": "B2B -> Analytics",
    "launched_at": 1755488960,
    "tags": [
      "Machine Learning",
      "SaaS",
      "Computer Vision",
      "B2B",
      "Video"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Analytics"
    ],
    "regions": [
      "Canada",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/ondeck-ai",
    "api": "https://yc-oss.github.io/api/batches/summer-2025/ondeck-ai.json"
  },
  {
    "id": 30821,
    "name": "Efference",
    "slug": "efference",
    "former_names": [
      "Remnant Robotics"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/5e2b6583b762823b5a584f08e551758f4d63fa39.png",
    "website": "https://efference.ai",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Efference builds the eyes and visual cortex for robots. Instead of treating depth as a hardware problem, we use software — inspired by how humans see — to generate rich and reliable 3D information. This lets us deliver higher performance and greater ease of use at a lower price than existing stereo cameras.",
    "one_liner": "We build the eyes and visual cortex for robots.",
    "team_size": 1,
    "industry": "Industrials",
    "subindustry": "Industrials -> Manufacturing and Robotics",
    "launched_at": 1762259214,
    "tags": [
      "Artificial Intelligence",
      "Machine Learning",
      "Robotics",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Fall 2025",
    "status": "Active",
    "industries": [
      "Industrials",
      "Manufacturing and Robotics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/efference",
    "api": "https://yc-oss.github.io/api/batches/fall-2025/efference.json"
  },
  {
    "id": 30845,
    "name": "Structured AI",
    "slug": "structured-ai",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/7b994637fa890bb7d41d69d022b3d15f6e4f3e8c.png",
    "website": "https://www.getstructured.ai/",
    "all_locations": "",
    "long_description": "Structured AI is building the AI workforce for construction design engineering, starting with AI agents that perform quality control on technical documents and drawings. Our agents learn your standards, apply the right building codes, and automatically review your drawings, so you see fewer clashes, fewer inconsistencies, and fewer costly RFIs and change orders.\r\n\r\n⚙️ Automates QA/QC across mechanical, electrical, structural and more\r\n🧩 Used by multi-disciplinary design firms to deliver projects faster with less risk\r\n🚀 Mission: Free engineers to focus on creative design, not repetitive admin",
    "one_liner": "AI workforce for Construction Engineering",
    "team_size": 5,
    "industry": "Real Estate and Construction",
    "subindustry": "Real Estate and Construction -> Construction",
    "launched_at": 1759212406,
    "tags": [
      "Computer Vision",
      "Construction",
      "Architecture",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Fall 2025",
    "status": "Active",
    "industries": [
      "Real Estate and Construction",
      "Construction"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/structured-ai",
    "api": "https://yc-oss.github.io/api/batches/fall-2025/structured-ai.json"
  },
  {
    "id": 30857,
    "name": "Aspect",
    "slug": "aspect-inc",
    "former_names": [
      "Auler"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/172f5fb23b85c343374cfa3c2b0a719eb64be3b6.png",
    "website": "https://aspect.inc",
    "all_locations": "",
    "long_description": "With our visual understanding engine & platform, Aspect data teams at AI labs.\r\n\r\nAspect processes dense multimodal datasets, providing tools for segmentation, QC, structured schema extraction. \r\n\r\nCompanies today have access to Glean and Notion Agents for working with vast text corpuses - Aspect is enabling that for multimodal data.",
    "one_liner": "AI Visual Understanding for Multimodal Data ",
    "team_size": 3,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1761607655,
    "tags": [
      "Artificial Intelligence",
      "Computer Vision",
      "B2B",
      "Video",
      "Media"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Fall 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/aspect-inc",
    "api": "https://yc-oss.github.io/api/batches/fall-2025/aspect-inc.json"
  },
  {
    "id": 30871,
    "name": "PlayVision",
    "slug": "playvision",
    "former_names": [
      "PlayVision AI",
      "PlayVision",
      "PlayVision AI"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/6f6f00ebc0225a4cbce95222a692d004481c7b1f.png",
    "website": "https://withplayvision.ai/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "PlayVision is the AI Moneyball for Sports: the future for scouting, recruiting, and playing the game.\r\n\r\nBasketball teams upload their practices or games, and PlayVision uses AI and computer vision to automatically tag and analyze the film, giving coaches and scouts 10 times the information on their players and their opponents. PlayVision also uses algorithms to rank every single college and professional basketball player in the country with over 40 different metrics from tracking and play-by-play data. \r\n\r\nCheck out our website at withplayvision.ai, and follow our instagram @playvisionai!",
    "one_liner": "AI Moneyball for Sports",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Analytics",
    "launched_at": 1761579619,
    "tags": [
      "Sports Tech",
      "Computer Vision",
      "Analytics",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Fall 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Analytics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/playvision",
    "api": "https://yc-oss.github.io/api/batches/fall-2025/playvision.json"
  },
  {
    "id": 30895,
    "name": "Allus AI",
    "slug": "allus-ai",
    "former_names": [
      "Allus AI Inc."
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/e556d72ba8162e6d77731f52ccea802c98b54fa3.png",
    "website": "https://allus.ai",
    "all_locations": "Atlanta, GA, USA",
    "long_description": "Allus builds next-gen vision foundation models that bring real intelligence to manufacturing. Enabling factories to see, understand, and improve production in real time. ",
    "one_liner": "Transforming manufacturing with our next-gen Vision Foundation Model",
    "team_size": 3,
    "industry": "Industrials",
    "subindustry": "Industrials -> Manufacturing and Robotics",
    "launched_at": 1761108820,
    "tags": [
      "Machine Learning",
      "SaaS",
      "Computer Vision",
      "Manufacturing",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Fall 2025",
    "status": "Active",
    "industries": [
      "Industrials",
      "Manufacturing and Robotics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/allus-ai",
    "api": "https://yc-oss.github.io/api/batches/fall-2025/allus-ai.json"
  },
  {
    "id": 30933,
    "name": "Nucleo",
    "slug": "nucleo",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/c489d64c631359b79077be36194f234ac5e83b2c.png",
    "website": "https://nucleoresearch.com/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "We help oncologists and radiologists extract insights from CT scans to support tumor characterization and treatment.\r\n\r\nThe hospitals we work with include Stanford Hospital, Cedars-Sinai (the largest hospital in California), UCI Health, and Weill Cornell.",
    "one_liner": "The first Agentic platform for Oncology",
    "team_size": 2,
    "industry": "Healthcare",
    "subindustry": "Healthcare",
    "launched_at": 1761179954,
    "tags": [
      "Machine Learning",
      "Computer Vision",
      "Health Tech"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Fall 2025",
    "status": "Active",
    "industries": [
      "Healthcare"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/nucleo",
    "api": "https://yc-oss.github.io/api/batches/fall-2025/nucleo.json"
  },
  {
    "id": 31094,
    "name": "Lexius",
    "slug": "lexius",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/3f713f0f123c886d7ce59127e88d9c062f767183.png",
    "website": "https://www.lexius.ai",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "We turn existing store security cameras into an AI system that catches shoplifting in real time and alerts staff before thieves leave.",
    "one_liner": "AI Crime Detection",
    "team_size": 3,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1766833804,
    "tags": [
      "Artificial Intelligence",
      "SaaS",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2026",
    "status": "Active",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/lexius",
    "api": "https://yc-oss.github.io/api/batches/winter-2026/lexius.json"
  },
  {
    "id": 31141,
    "name": "OctaPulse",
    "slug": "octapulse",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/23da3a492d96b19d0437b960a02a4a3614f0c79c.png",
    "website": "https://www.tryoctapulse.com/",
    "all_locations": "Remote",
    "long_description": "OctaPulse uses AI vision to automate hatchery QA for fish farms, starting with broodstock phenotyping and juvenile deformity inspection. We cut inspection time from about 5 minutes to under 30 seconds per fish, with more than 90 percent accuracy, so farms advance only high quality fish and waste less feed and labor. Our goal is to bring automation across the entire fish production lifecycle for the $300B aquaculture industry.\r\n\r\nAquaculture is the fastest growing food sector, and has already surpassed commercial fishing for production of seafood. Yet two of the most critical QA and QC steps in fish production are still done by hand: phenotyping and deformity inspection. These processes are slow, error prone, and despised by technicians but vital for the success of the farm, so much so that farms spend >$200K a year on trained technicians and geneticists to operate. We’ve built an AI vision platform for vertically integrated finfish farms that drops into existing workflows starting in the hatchery, uses off the shelf cameras, standardizes these QA steps, and creates a proprietary multi species dataset that becomes the brain for future autonomous aquafarms. Phenotyping is the start, but the platform is designed to be a drop in solution that can easily expand into feeding, health monitoring, and processing so we can solve production problems across the lifecycle.\r\n\r\n We signed a 6-figure paid pilot with the largest trout producer in the United States, are deploying into 2 more farms early 2026, and trained models above 90 percent accuracy while cutting inspection time from 5 minutes to under 30 seconds. Each deployment adds labeled images to our dataset and improves cross species generalization.\r\n",
    "one_liner": "Computer vision to automate fish farming from hatchery to harvest",
    "team_size": 2,
    "industry": "Industrials",
    "subindustry": "Industrials -> Climate",
    "launched_at": 1766417530,
    "tags": [
      "Robotics",
      "Computer Vision",
      "Food Tech"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2026",
    "status": "Active",
    "industries": [
      "Industrials",
      "Climate"
    ],
    "regions": [
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/octapulse",
    "api": "https://yc-oss.github.io/api/batches/winter-2026/octapulse.json"
  },
  {
    "id": 31145,
    "name": "RamAIn",
    "slug": "ramain",
    "former_names": [
      "Ramain"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/9fe951afa5872a811734029111550a11062d931e.png",
    "website": "https://ramain.ai",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "RamAIn can intelligently automate any super complex and repetitive process across applications (Windows + Mac + Browser + Desktop) super-duper fast. It doesn’t matter whether you have API access or not - if you can see it, RamAIn can do it.\r\n\r\nCurrent CUAs all follow the same decision loop: screenshot, VLM, decision, repeat. This is expensive, unreliable and slow. We build infrastructure to pre-train CUAs on specific interfaces, effectively teaching RamAIn to use your computer.",
    "one_liner": "Super fast computer-use agents to automate complex workflows.",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1767663208,
    "tags": [
      "Machine Learning",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2026",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/ramain",
    "api": "https://yc-oss.github.io/api/batches/winter-2026/ramain.json"
  }
]
