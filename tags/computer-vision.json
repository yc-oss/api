[
  {
    "id": 30,
    "name": "Matterport",
    "slug": "matterport",
    "former_names": [
      "MatterPort"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b271a79c3b59d6344c90e2803525a22f2a5e8406.png",
    "website": "http://matterport.com",
    "all_locations": "Sunnyvale, CA, USA",
    "long_description": "Matterport is an immersive media technology company that is shaking up the 3D / VR world.  Our team has built the first end-to-end system for creating, modifying, distributing, and navigating immersive 3D and virtual reality (VR) versions of real-world spaces on web and mobile devices. Matterport offers the world's most inexpensive and simplest way to capture 3D spaces. \r\n\r\nOur products include:\r\n- Matterport Pro Camera for capturing real spaces in 3D.  It collects accurate visual and spatial data to map entire areas in minutes and is all about automation and ease of use.\r\n- The Matterport Cloud for processing and hosting 3D models\r\n- Matterport Portal, our system for viewing, editing, and managing models; collaborating with colleagues; and sharing models with others\r\n- Matterport 3D Showcase, a browser-based 3D media player, which allows anyone to view 3D models in their browser with no additional software\r\n- Matterport Core VR: All Spaces can be converted to VR and experienced on Samsung Gear VR or Google Cardboard (in beta), with additional device support coming soon.\r\n\r\nMatterport 3D media solutions power industries from real estate (residential, multi-family and commercial) and travel and hospitality (hotels, vacation rentals, and venue booking), to business listings, architecture, engineering and construction, news and entertainment, and everything in between. \r\n\r\nWe’re growing fast. If you’re passionate about solving cutting-edge problems in computer vision and hardware design and creating order-of-magnitude improvements in the ability to easily create and share 3D models of real world spaces, we want to talk to you. See open positions at matterport.com/jobs.\r\n\r\nTry Matterport for yourself at matterport.com/try.",
    "one_liner": "Turn physical objects and environments into 3D models in seconds.",
    "team_size": 201,
    "industry": "Consumer",
    "subindustry": "Consumer -> Virtual and Augmented Reality",
    "launched_at": 1322045771,
    "tags": [
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": true,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2012",
    "status": "Public",
    "industries": [
      "Consumer",
      "Virtual and Augmented Reality"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/matterport",
    "api": "https://yc-oss.github.io/api/batches/winter-2012/matterport.json"
  },
  {
    "id": 50,
    "name": "Flutter",
    "slug": "flutter",
    "former_names": [],
    "small_logo_thumb_url": "/company/thumb/missing.png",
    "website": "http://flutterapp.com",
    "all_locations": "Santa Monica, CA, USA",
    "long_description": "Flutter is recreating the magic of seeing someone in real-life for the first time, on your phone.\n\nFlutter lets you record short, ephemeral videos to express yourself and capture the attention of potential matches nearby. Users browse through nearby videos and, just like Tinder, like or pass on each one before moving on to the next.\n\nHere’s the catch: to actually match with someone, you have to be on the app at the same time and look into each other’s eyes for 15 seconds to see if there’s a spark. We help users play this game by sending push notifications when people they like are online.\n\nVideo is so powerful. We've seen this with YouTube, Snapchat, Meerkat. And 15 seconds of live, two-way video can tell you so much more about a person than hand-picked photos and bios.",
    "one_liner": "Flutter combined computer vision technology with the built-in webcams…",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1322045950,
    "tags": [
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2012",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/flutter",
    "api": "https://yc-oss.github.io/api/batches/winter-2012/flutter.json"
  },
  {
    "id": 175,
    "name": "SimplyListed",
    "slug": "simplylisted",
    "former_names": [],
    "small_logo_thumb_url": "/company/thumb/missing.png",
    "website": "http://simplylisted.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "SimplyListed makes it really easy for people to sell their stuff. You just take a picture, and they list your item for sale automatically.\r\n\r\nA prototype of the SimplyListed iPhone app was first released on the iTunes App Store in February 2011.",
    "one_liner": "Sell your stuff.",
    "team_size": 2,
    "industry": "Consumer",
    "subindustry": "Consumer -> Home and Personal",
    "launched_at": 1326790047,
    "tags": [
      "Marketplace",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2011",
    "status": "Inactive",
    "industries": [
      "Consumer",
      "Home and Personal"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/simplylisted",
    "api": "https://yc-oss.github.io/api/batches/winter-2011/simplylisted.json"
  },
  {
    "id": 193,
    "name": "GazeHawk",
    "slug": "gazehawk",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/7b6bb6a40cbe23dd398442068cb5d69e8e784f57.png",
    "website": "http://gazehawk.com",
    "all_locations": "Mountain View, CA, USA",
    "long_description": "GazeHawk provides low-cost eye tracking technology for use in usability studies and ad evaluation.  Our proprietary technology allows us to use ordinary webcams to run studies.  This enables in-home eye tracking, as well as fast, affordable large-scale studies.http://www.gazehawk.com/",
    "one_liner": "Eyetracking using webcams.",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1326790180,
    "tags": [
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2010",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/gazehawk",
    "api": "https://yc-oss.github.io/api/batches/summer-2010/gazehawk.json"
  },
  {
    "id": 679,
    "name": "VizeraLabs",
    "slug": "vizeralabs",
    "former_names": [],
    "small_logo_thumb_url": "/company/thumb/missing.png",
    "website": "http://vizeralabs.com",
    "all_locations": "Sunnyvale, CA, USA",
    "long_description": "Vizera was an augmented reality company that used projectors with depth sensors to project an AR layer onto real world objects, rather than using screens/smart glasses. \r\n\r\nOur first application was in retail where we partnered with top furniture retailers to display their selection of different fabrics/patterns by using our projectors in their smaller showrooms to improve their in store revenue. \r\n\r\nOur demo is still live on YouTube: https://www.youtube.com/watch?v=5YV8lo-OxZQ ",
    "one_liner": "Augmented reality through projectors",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1398907794,
    "tags": [
      "Augmented Reality",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2014",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/vizeralabs",
    "api": "https://yc-oss.github.io/api/batches/summer-2014/vizeralabs.json"
  },
  {
    "id": 822,
    "name": "Dabble",
    "slug": "dabble",
    "former_names": [
      "Perceptiv Labs",
      "Vertical",
      "Placenote"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/ded86f0a0f49180c787803bef08563dd167f5851.png",
    "website": "https://dabble.so",
    "all_locations": "Toronto, ON, Canada; Remote",
    "long_description": "Dabble is a virtual photo studio for e-commerce powered by hyper-realistic CGI and computer vision. The demand for content in retail is skyrocketing due to the pandemic induced surge in online shopping, but product photography is still extremely slow, tedious and expensive. We’re building a platform to scale and automate product photography for every e-commerce brand.",
    "one_liner": "A synthetic photo studio for e-commerce",
    "team_size": 3,
    "industry": "B2B",
    "subindustry": "B2B -> Marketing",
    "launched_at": 1416309244,
    "tags": [
      "Artificial Intelligence",
      "Augmented Reality",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2015",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Marketing"
    ],
    "regions": [
      "Canada",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/dabble",
    "api": "https://yc-oss.github.io/api/batches/winter-2015/dabble.json"
  },
  {
    "id": 832,
    "name": "Standard Cyborg",
    "slug": "standard-cyborg",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/ea641cf296beace7a7288415d4808dc519f3a987.png",
    "website": "http://standardcyborg.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "We are multiplying the potential of the real world by making computer vision accessible to all.\r\n\r\nWe create the cloud and edge tools that developers and non-developers require in order to build, deploy, and improve CV solutions quickly.\r\n\r\nstandardcyborg.com (YC W15)",
    "one_liner": "Buid, test and deploy perception applications",
    "team_size": 9,
    "industry": "Healthcare",
    "subindustry": "Healthcare -> Medical Devices",
    "launched_at": 1416310916,
    "tags": [
      "Machine Learning",
      "Computer Vision",
      "Open Source"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2015",
    "status": "Inactive",
    "industries": [
      "Healthcare",
      "Medical Devices"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/standard-cyborg",
    "api": "https://yc-oss.github.io/api/batches/winter-2015/standard-cyborg.json"
  },
  {
    "id": 856,
    "name": "Mashgin",
    "slug": "mashgin",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/bd7ff2b3db9bbbc82a79afababdad873d16b6e54.png",
    "website": "http://mashgin.com",
    "all_locations": "Palo Alto, CA, USA",
    "long_description": "Mashgin creates better retail experiences through visual automation. \r\n\r\nWe’ve built a self-checkout kiosk that uses computer vision to scan multiple items without barcodes, reducing checkout time by 10x. We’re completely recreating the checkout experience in an industry that’s had little innovation in decades.\r\n\r\nOur clients see dramatic reductions in lines and revenue increases of as much as 400% as a result.",
    "one_liner": "Self-Checkout using Computer Vision.",
    "team_size": 75,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1421189374,
    "tags": [
      "Cashierless Checkout",
      "Deep Learning",
      "Hardware",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2015",
    "status": "Active",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/mashgin",
    "api": "https://yc-oss.github.io/api/batches/winter-2015/mashgin.json"
  },
  {
    "id": 929,
    "name": "Prayas Analytics",
    "slug": "prayas-analytics",
    "former_names": [
      "Prayas Analytics MetricBoy",
      "SimpleMoney"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/5239f1a49fa06d125e98d56bb9e5a5fd04d9f05a.png",
    "website": "http://prayasanalytics.com",
    "all_locations": "New York, NY, USA",
    "long_description": "Prayas Anaytics helped retailers A/B test their stores, the way eCommerce companies A/B test their websites. We did this by continuously collecting data on customer movement using existing security cameras already in a retailer's stores. \r\n\r\nWe were a Y Combinator backed company (S15) and worked with several retailers including Barneys, Payomatic, and multiple Fortune 200 retailers.",
    "one_liner": "A/B testing for brick-and-mortar stores.",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1430156128,
    "tags": [
      "SaaS",
      "Computer Vision",
      "Retail Tech"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2015",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/prayas-analytics",
    "api": "https://yc-oss.github.io/api/batches/summer-2015/prayas-analytics.json"
  },
  {
    "id": 933,
    "name": "Reduced Energy Microsystems",
    "slug": "reduced-energy-microsystems",
    "former_names": [],
    "small_logo_thumb_url": "/company/thumb/missing.png",
    "website": "http://remicro.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Reduced Energy Microsystems is building the most power-efficient silicon for embedded computer vision to bring visual intelligence to a whole new range of devices. By combining  proprietary asynchronous resilient technology with a custom neural network architecture, REM chips will handle state-of-the-art inference and traditional vision workloads in a tiny power envelope. REM makes  augmented reality, body-worn cameras, and autonomous robots smarter than ever before.",
    "one_liner": "Building the lowest-power silicon for embedded deep learning and…",
    "team_size": 2,
    "industry": "Industrials",
    "subindustry": "Industrials -> Manufacturing and Robotics",
    "launched_at": 1430156130,
    "tags": [
      "Artificial Intelligence",
      "Hardware",
      "Computer Vision",
      "Energy"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2015",
    "status": "Inactive",
    "industries": [
      "Industrials",
      "Manufacturing and Robotics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/reduced-energy-microsystems",
    "api": "https://yc-oss.github.io/api/batches/summer-2015/reduced-energy-microsystems.json"
  },
  {
    "id": 936,
    "name": "Shape (ShapeScale)",
    "slug": "shape-shapescale",
    "former_names": [
      "ShapeScale"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/51a78fd63bb7c35e64c4b0654f44569b121ca09b.png",
    "website": "https://shapescale.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Shape is a health tech startup based in San Francisco, California. We are backed by Y Combinator and the company is led by experienced hardware serial entrepreneurs. Shape has designed a product called ShapeScale. ShapeScale is transforming the way we measure our health goals by enabling you to visualize yourself in 3D and see where you have been losing fat and gaining muscle.",
    "one_liner": "ShapeScale is a personal 3D scanner and fitness tracker that…",
    "team_size": 7,
    "industry": "Consumer",
    "subindustry": "Consumer -> Consumer Electronics",
    "launched_at": 1430156131,
    "tags": [
      "Hardware",
      "Computer Vision",
      "Consumer Health Services"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2015",
    "status": "Active",
    "industries": [
      "Consumer",
      "Consumer Electronics"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/shape-shapescale",
    "api": "https://yc-oss.github.io/api/batches/summer-2015/shape-shapescale.json"
  },
  {
    "id": 999,
    "name": "Focal Systems",
    "slug": "focal-systems",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/e25ba04ae8686807d958c48f1372502741b4b2e3.png",
    "website": "http://www.focal.systems",
    "all_locations": "New York, NY, USA; San Francisco, CA, USA; Toronto, ON, Canada; London, England, United Kingdom",
    "long_description": "Focal Systems is on a mission to lower the cost of living for all mankind by automating and optimizing Brick and Mortar Retail with the latest advancements in AI. Focal Systems is the industry leader in retail automation solutions. By digitizing store shelves hourly and unleashing FocalOS, retailers unlock huge operational efficiencies, optimized merchandising, and streamlined supply chains which deliver impactful financial results. Focal is transforming retail by empowering store management to make automated, data-driven decisions. We are the operating system of retail.",
    "one_liner": "Building the Operating System for B&M Retail using Deep Learning",
    "team_size": 170,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1447280416,
    "tags": [
      "Deep Learning",
      "Grocery",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2016",
    "status": "Active",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "Canada",
      "United Kingdom",
      "America / Canada",
      "Europe",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/focal-systems",
    "api": "https://yc-oss.github.io/api/batches/winter-2016/focal-systems.json"
  },
  {
    "id": 1058,
    "name": "Caper",
    "slug": "caper",
    "former_names": [
      "QueueHop"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/45034c22d81491a4e49c2c46c3c822d2d820941d.png",
    "website": "https://www.caper.ai/",
    "all_locations": "",
    "long_description": "Caper focuses on compacting Amazon-Go's technology (image recognition, sensor fusion and artificial intelligence) into a smart shopping cart, allowing each shopper to throw her groceries into the cart and self-checkout without cashiers. The technology is looking to fundamentally transform physical retail and rapidly scale into existing grocery stores.",
    "one_liner": "Plug-and-play cashier-less retail powered by computer vision and AI",
    "team_size": 15,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1447654816,
    "tags": [
      "Artificial Intelligence",
      "Cashierless Checkout",
      "Computer Vision",
      "Retail Tech"
    ],
    "tags_highlighted": [],
    "top_company": true,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2016",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/caper",
    "api": "https://yc-oss.github.io/api/batches/winter-2016/caper.json"
  },
  {
    "id": 1221,
    "name": "Iris Automation",
    "slug": "iris-automation",
    "former_names": [],
    "small_logo_thumb_url": "/company/thumb/missing.png",
    "website": "http://www.irisonboard.com",
    "all_locations": "San Francisco, CA, USA; Remote",
    "long_description": "The future for autonomous industrial drones is in sight - Enabling safer drone operation through intelligent collision avoidance. We are a Y Combinator and Silicon Valley investor company with a team from NASA, Boeing and PhDs in computer vision. \r\nRead more at: https://tinyurl.com/y7tm4zr8\r\n \r\nWebsite: www.IrisOnBoard.com",
    "one_liner": "Enabling autonomous drone operations globally through AI software",
    "team_size": null,
    "industry": "Industrials",
    "subindustry": "Industrials -> Drones",
    "launched_at": 1461210618,
    "tags": [
      "Drones",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2016",
    "status": "Acquired",
    "industries": [
      "Industrials",
      "Drones"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/iris-automation",
    "api": "https://yc-oss.github.io/api/batches/summer-2016/iris-automation.json"
  },
  {
    "id": 1285,
    "name": "CrowdAI",
    "slug": "crowdai",
    "former_names": [
      "StenoAI"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/65641ddd8516f01cc3bf87dd2c876cd999d398f0.png",
    "website": "https://crowdai.com/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "CrowdAI equips enterprises of all sizes with the power of deep learning and the approachability and speed of no-code software.  Our easy-to-master platform allows users of all technical abilities, from business operators to data scientists, to power real-time decisions from their visual world.\r\n\r\nRecognizing data as the new code, CrowdAI is the only vision AI platform to truly provide organizations with the infrastructure for the entire AI-lifecycle, empowering you to label data systematically, train models efficiently, scale models iteratively, and power decisions continuously.",
    "one_liner": "CrowdAI is the world's leading no-code platform for vision AI",
    "team_size": 32,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1461817213,
    "tags": [
      "Machine Learning",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2016",
    "status": "Acquired",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/crowdai",
    "api": "https://yc-oss.github.io/api/batches/summer-2016/crowdai.json"
  },
  {
    "id": 1487,
    "name": "Ambient.ai",
    "slug": "ambient-ai",
    "former_names": [
      "Ambient"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/624d0ce6f387431048bed692cfded210ffc7d139.png",
    "website": "https://ambient.ai",
    "all_locations": "San Jose, CA, USA",
    "long_description": "Ambient.ai is a computer vision intelligence company transforming enterprise security operations to prevent security incidents before they happen. The Ambient.ai platform applies AI and computer vision intelligence to existing sensor and camera infrastructure to deliver continuous physical security monitoring and automate the immediate dispatch of human resources. Ambient.ai is the first platform that goes beyond basic motion detection and image recognition to achieve near-human perception with automated situational context. \r\n\r\nWith physical security incidents on the rise and physical security organizations left under-resourced, Ambient.ai’s computer intelligence platform comes at a time of critical need, which is why the company has raised over $50 million from venture capital investors led by a16z. Today, large enterprises, schools and organizations – including many of the largest US tech companies and other Fortune 500 companies – use Ambient.ai to secure property, people, and assets from the most harrowing physical security threats.\r\n\r\nThe company was founded in 2017 by experts in artificial intelligence from Stanford who previously built iconic products at Apple, Google, Microsoft and Dropbox. We are backed by Andreessen Horowitz (a16z), SV Angel, Y Combinator, and visionary angels like Jyoti Bansal, Mark Leslie and Elad Gil.",
    "one_liner": "AI company transforming enterprise physical security to prevent…",
    "team_size": 95,
    "industry": "B2B",
    "subindustry": "B2B -> Security",
    "launched_at": 1478224835,
    "tags": [
      "Computer Vision",
      "Security",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2017",
    "status": "Active",
    "industries": [
      "B2B",
      "Security"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/ambient-ai",
    "api": "https://yc-oss.github.io/api/batches/winter-2017/ambient-ai.json"
  },
  {
    "id": 1498,
    "name": "Veryfi, Inc.",
    "slug": "veryfi-inc",
    "former_names": [
      "IQB Labs",
      "IQBoxy",
      "Veryfi"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b363a44bfe1278786c4092bd157ce82f208e1a21.png",
    "website": "https://www.veryfi.com/",
    "all_locations": "San Mateo, CA, USA",
    "long_description": "Veryfi is a Data Transformation Platform turning Documents into Data in Seconds with Accuracy & Speed Surpassing Humans.\r\n\r\nVeryfi gives you a fully integrated suite of data transformation products for you to securely capture, extract and transform bills, receipts and invoices into structured data for use in your app, website or backoffice. To learn more https://www.veryfi.com/\r\n\r\nITS TIME TO BUILD\r\nVeryfi's developer friendly toolkits enable superior products that automate Expense Management, AP/Bill Pay, Bookkeeping and provide consumer spend behavior in Market Research\r\n\r\nInvoices, Bills & POs\r\n10 mins of data entry per invoice? No way! 5 seconds and it's done. Untap a goldmine of data down to line-items.\r\n\r\nExpense Receipts\r\nNo more painful data entry for expense reimbursement. Bonus: comply with new data privacy regulations.\r\n\r\nFMCG/CPG Receipts\r\nData is the new oil. Understand consumer spend across retail from SKUs in seconds.\r\n\r\nHotel Folios\r\nSupercharge your travel & expense management product with a wealth of data minus the tedious data entry.\r\n\r\nW-2 Tax Form β\r\nExtract every drop of tax data from W2s in seconds. Including handwritten notes, checkboxes and multi-lines.\r\n\r\nCards β\r\nCapture and extract data Credit Cards, Business Cards and Healthcare Insurance Cards in seconds.\r\n\r\nMore: https://www.veryfi.com/",
    "one_liner": "APIs to Liberate Trapped Data in Unstructured Documents",
    "team_size": 60,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1478227238,
    "tags": [
      "Machine Learning",
      "Computer Vision",
      "API",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2017",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/veryfi-inc",
    "api": "https://yc-oss.github.io/api/batches/winter-2017/veryfi-inc.json"
  },
  {
    "id": 1557,
    "name": "Mirror AI",
    "slug": "mirror-ai",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/410226e6cc4a405060b8845ca57a12726472ea14.png",
    "website": "http://mirror-ai.com",
    "all_locations": "San Francisco, CA, USA; Remote",
    "long_description": "Mirror Emoji Keyboard by Mirror AI is an app that takes a photo of your face and creates you a set of personalized emoji. You get hundreds of them ready to be shared on messengers or social networks.",
    "one_liner": "App that turns selfie photos into thousand emoji that look like you…",
    "team_size": 7,
    "industry": "Consumer",
    "subindustry": "Consumer -> Social",
    "launched_at": 1481775630,
    "tags": [
      "Computer Vision",
      "Entertainment"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2017",
    "status": "Active",
    "industries": [
      "Consumer",
      "Social"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/mirror-ai",
    "api": "https://yc-oss.github.io/api/batches/winter-2017/mirror-ai.json"
  },
  {
    "id": 1583,
    "name": "Skyways",
    "slug": "skyways",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/8778c5906bf88db6cb40cb2a78663ccf433c8d21.png",
    "website": "http://skyways.com",
    "all_locations": "Austin, TX, USA",
    "long_description": "",
    "one_liner": "Creating a new form of air transportation.",
    "team_size": 23,
    "industry": "Industrials",
    "subindustry": "Industrials -> Drones",
    "launched_at": 1493063490,
    "tags": [
      "Air Taxis",
      "Computer Vision",
      "AI",
      "ML"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2017",
    "status": "Active",
    "industries": [
      "Industrials",
      "Drones"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/skyways",
    "api": "https://yc-oss.github.io/api/batches/summer-2017/skyways.json"
  },
  {
    "id": 1858,
    "name": "Jido Maps",
    "slug": "jido-maps",
    "former_names": [
      "MapSync"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/788dc05b2141606cea9f6805759306ec0ea99f5e.png",
    "website": "https://jidomaps.com/",
    "all_locations": "Berkeley, CA, USA; San Francisco, CA, USA; Remote",
    "long_description": "We help teams that may or may not have machine learning expertise quickly turn their data into deployed computer vision models. Example applications include security camera monitoring, automating data entry, interpreting web scraped images, validated user photo inputs, augmented reality and mobile product scanning. \r\n\r\nIf you have visual or scanned data that you wish your software could interpret at scale, we can turn around a first proof of concept in under a week. Reach out and see how computer vision can change your business.",
    "one_liner": "Turn your data into a deployed computer vision model",
    "team_size": 6,
    "industry": "B2B",
    "subindustry": "B2B -> Infrastructure",
    "launched_at": 1512529341,
    "tags": [
      "Deep Learning",
      "Indoor Mapping",
      "Machine Learning",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2018",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Infrastructure"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/jido-maps",
    "api": "https://yc-oss.github.io/api/batches/winter-2018/jido-maps.json"
  },
  {
    "id": 1910,
    "name": "Activeloop",
    "slug": "activeloop",
    "former_names": [
      "Snark.ai",
      "Snark AI"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/c516ed5054847ecb1afb63f795f712b8d5c7f23d.png",
    "website": "https://activeloop.ai/",
    "all_locations": "Mountain View, CA, USA",
    "long_description": "We provide a simple API for creating, storing, versioning, and collaborating on multi-modal AI datasets of any size. With Activeloop's open-core stack, you can rapidly transform and stream data while training models at scale. Deep Lake powers foundational model training by acting as a vector database with significant benefits, such as (1) the ability to use multi-modal datasets to fine-tune your own LLM models, (2) storing both the embeddings and the original data with automatic version control, so no embedding re-computation is needed (3) truly serverless service with no vendor lock-in. How cool is that?\r\n\r\nGitHub loves us - we're one of the fastest-growing libraries there, and we're used by little-known companies like Google, Waymo, and Intel. No big deal. \r\n\r\nOur founding team hails from places like Princeton, Stanford, Google, and Tesla, and we're backed by Y Combinator & other Silicon Valley heavyweights. \r\n\r\nActiveloop is hiring, and we want you! Check out our open roles on our YC page and join the fun.\r\n\r\n10-min demo: https://activeloop.wistia.com/medias/aibvo0dst2\r\nWhitepaper: https://www.deeplake.ai/whitepaper",
    "one_liner": "Database for AI",
    "team_size": 15,
    "industry": "B2B",
    "subindustry": "B2B -> Infrastructure",
    "launched_at": 1524690140,
    "tags": [
      "Computational Storage",
      "Deep Learning",
      "Generative AI",
      "Computer Vision",
      "Open Source"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2018",
    "status": "Active",
    "industries": [
      "B2B",
      "Infrastructure"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/activeloop",
    "api": "https://yc-oss.github.io/api/batches/summer-2018/activeloop.json"
  },
  {
    "id": 1945,
    "name": "LabelFlow",
    "slug": "labelflow",
    "former_names": [
      "Sterblue"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/799423cdb14bc1fbe4eb1d647eedf74d0a22e8c7.png",
    "website": "https://labelflow.ai/",
    "all_locations": "Nantes, Pays de la Loire, France; Remote",
    "long_description": "At LabelFlow, we build GitHub for visual data. Our mission is to facilitate and accelerate the development of AI at scale thanks to top-notch labeling tools and a dataset marketplace.",
    "one_liner": "GitHub for visual data",
    "team_size": 6,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1525147499,
    "tags": [
      "Computer Vision",
      "Data Engineering",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2018",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "France",
      "Europe",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/labelflow",
    "api": "https://yc-oss.github.io/api/batches/summer-2018/labelflow.json"
  },
  {
    "id": 11895,
    "name": "Overview",
    "slug": "overview",
    "former_names": [
      "Overview.ai"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/cd1326e4f02e779f1009ae931cfeb26eb1eb20b7.png",
    "website": "https://overview.ai",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Overview is a company that takes the cutting edge in computer vision and deep learning and applies it to previously unsolvable manufacturing inspection problems. We are truly a full stack company. We install physical cameras into the facility, run inference on the edge and manage massive deployments. Overview also streams gigabytes of video/image data to the cloud for our web platform to give customers advanced insights and analytics. ",
    "one_liner": "AI vision sensors for manufacturing",
    "team_size": 15,
    "industry": "B2B",
    "subindustry": "B2B -> Operations",
    "launched_at": 1538509310,
    "tags": [
      "Deep Learning",
      "IoT",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2019",
    "status": "Active",
    "industries": [
      "B2B",
      "Operations"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/overview",
    "api": "https://yc-oss.github.io/api/batches/winter-2019/overview.json"
  },
  {
    "id": 11961,
    "name": "Sorting Robotics",
    "slug": "sorting-robotics",
    "former_names": [
      "Robotic Sorting Solutions"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/2dfc5eeb06e8051af24bd5a9c7758dbe219fba21.png",
    "website": "https://www.sortingrobotics.com/",
    "all_locations": "Los Angeles, CA, USA",
    "long_description": "",
    "one_liner": "We create automation technology for the cannabis industry.",
    "team_size": 12,
    "industry": "B2B",
    "subindustry": "B2B -> Supply Chain and Logistics",
    "launched_at": 1541124183,
    "tags": [
      "Robotic Process Automation",
      "Robotics",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2019",
    "status": "Active",
    "industries": [
      "B2B",
      "Supply Chain and Logistics"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/sorting-robotics",
    "api": "https://yc-oss.github.io/api/batches/winter-2019/sorting-robotics.json"
  },
  {
    "id": 12080,
    "name": "Aura Vision",
    "slug": "aura-vision",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/06dd0022a30071b010e7c41ab3e012079397a6d2.png",
    "website": "https://auravision.ai",
    "all_locations": "London, England, United Kingdom",
    "long_description": "Aura Vision is like Google Analytics for physical stores. We help retailers make more sales by using their existing security cameras and our plug & play AI to better measure their customers and stores.",
    "one_liner": "Visitor analytics for physical retail stores using existing security…",
    "team_size": 10,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1541648089,
    "tags": [
      "SaaS",
      "IoT",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2019",
    "status": "Active",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United Kingdom",
      "Europe",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/aura-vision",
    "api": "https://yc-oss.github.io/api/batches/winter-2019/aura-vision.json"
  },
  {
    "id": 12271,
    "name": "Allure Systems",
    "slug": "allure-systems",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/876f66dff22e97cba80fe969792f2c63dd568d79.png",
    "website": "http://www.alluresystems.com/",
    "all_locations": "New York, NY, USA",
    "long_description": "Allure Systems was Acquired by Farfetch (NASDAQ: FTCH) in Dec 2021. AllureSystems uses generative A.I. to create stunning apparel images for eCommerce. Allure works with leading fashion retailers to improve conversion rates by creating images that resonate with their clients in a scalable and cost-effective way. \r\nWith a single photo of clothing,  a brand can produce unlimited images, on any model, instantly.  The ability to show styles on models in every size increases conversion rates and wow the customers. Without needing models or photographers on-site, brands can produce images for their product page at scale.\r\n",
    "one_liner": "A.I. to create stunning fashion images for eCommerce. ",
    "team_size": 18,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1544065373,
    "tags": [
      "Generative AI",
      "Computer Vision",
      "E-commerce",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2019",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/allure-systems",
    "api": "https://yc-oss.github.io/api/batches/winter-2019/allure-systems.json"
  },
  {
    "id": 12846,
    "name": "Traces",
    "slug": "traces",
    "former_names": [
      "EllipseAI"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/95c9d28f031050f88288e5b80195b4ca69c2dd41.png",
    "website": "https://www.traces.ai",
    "all_locations": "Mountain View, CA, USA",
    "long_description": "We analyze thousands of video streams to find and track people without facial recognition. \r\nOur tech is available as an API and has multiple use cases. Unique people counting, forensic people search, falsa alarm filtering and many more. \r\n",
    "one_liner": "Transform your video monitoring with AI",
    "team_size": 10,
    "industry": "B2B",
    "subindustry": "B2B -> Security",
    "launched_at": 1559260859,
    "tags": [
      "Artificial Intelligence",
      "Deep Learning",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2019",
    "status": "Active",
    "industries": [
      "B2B",
      "Security"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/traces",
    "api": "https://yc-oss.github.io/api/batches/summer-2019/traces.json"
  },
  {
    "id": 13109,
    "name": "Taiv",
    "slug": "taiv",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/517858a2f6d1535b89d71bd9bf5a0f334c3c7f8d.png",
    "website": "https://taiv.tv",
    "all_locations": "Winnipeg, MB, Canada",
    "long_description": "Taiv puts TVs on autopilot, automatically switching between cable, our own streaming channels, digital signage, and trivia.  Our proprietary AI model analyzes the live video feed and intelligently switches sources during commercial breaks, show changes, or based on the time of day, to show the best possible content & ads for any environment.\r\n\r\nWe offer this for free to venues and make money by selling ads, which we rev-share back with the venue, turning their TVs from a cost center to a profit center. ",
    "one_liner": "Taiv uses AI to make businesses TVs more entertaining & valuable.",
    "team_size": 40,
    "industry": "B2B",
    "subindustry": "B2B -> Marketing",
    "launched_at": 1584223249,
    "tags": [
      "Marketplace",
      "Computer Vision",
      "B2B",
      "Advertising",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2020",
    "status": "Active",
    "industries": [
      "B2B",
      "Marketing"
    ],
    "regions": [
      "Canada",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/taiv",
    "api": "https://yc-oss.github.io/api/batches/winter-2020/taiv.json"
  },
  {
    "id": 13307,
    "name": "Photoroom",
    "slug": "photoroom",
    "former_names": [
      "Artizans",
      "PhotoRoom"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/e5f5e5ed0c922fb566fac15578940996a8f6a930.png",
    "website": "https://photoroom.com/",
    "all_locations": "Paris, Île-de-France, France",
    "long_description": "Photoroom provides photo editing software powerful enough to create outstanding images yet simple enough to be used without any training. We leverage deep learning to translate pixels into objects, drastically simplifying non-creative tasks such as removing backgrounds from images.\r\n\r\nOur mission: enable entrepreneurs and small businesses to compose images that stand out.",
    "one_liner": "Power commerce photography with generative AI",
    "team_size": 100,
    "industry": "Consumer",
    "subindustry": "Consumer -> Content",
    "launched_at": 1596474431,
    "tags": [
      "Generative AI",
      "Computer Vision",
      "Design Tools",
      "API",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2020",
    "status": "Active",
    "industries": [
      "Consumer",
      "Content"
    ],
    "regions": [
      "France",
      "Europe",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Growth",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/photoroom",
    "api": "https://yc-oss.github.io/api/batches/summer-2020/photoroom.json"
  },
  {
    "id": 13472,
    "name": "Oda",
    "slug": "oda",
    "former_names": [
      "Zappeal",
      "Oda",
      "Oda (was Zappeal)"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b282b3863a1e15b0e08e9b79cf5ac972840f5523.png",
    "website": "https://www.odastudio.ai/?ref=yc",
    "all_locations": "Los Angeles, CA, USA; Remote",
    "long_description": "Oda is an AI agent for home design. Homebuyers and renters alike can use Oda to discover their interior design preferences, apply those preferences to their new home, and then find the best furniture, décor, and appliances aggregated from many different online retailers. Oda distributes its product to homebuyers and renters through partnerships with real estate companies and platforms. Real estate partners add Oda AI iFrames to their websites to showcase listed homes with AI-generated designs. Each AI iFrame is directly linked to an Oda board, allowing consumers to transition from an iFrame to Oda to further personalize the designs and create their dream home.",
    "one_liner": "AI Agent for Home Design",
    "team_size": 9,
    "industry": "B2B",
    "subindustry": "Real Estate and Construction -> Housing and Real Estate",
    "launched_at": 1584035955,
    "tags": [
      "Machine Learning",
      "Computer Vision",
      "E-commerce",
      "AI Assistant"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2020",
    "status": "Active",
    "industries": [
      "B2B",
      "Marketing"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/oda",
    "api": "https://yc-oss.github.io/api/batches/winter-2020/oda.json"
  },
  {
    "id": 21769,
    "name": "Roboflow",
    "slug": "roboflow",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/ba0036069bd338a4c6188cb137722d8f584d0016.png",
    "website": "https://roboflow.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Roboflow enables developers to make the world programmable.\r\n\r\nUse our tools to build better datasets (collect image, video / annotate), models (foundation and fine tuned small models), and deployments (self hosted, edge, APIs, SDKs) for computer vision. Over 250k developers, including those from over half the Fortune 100, build with our open source and hosted tools.\r\n\r\nBuild with us: https://app.roboflow.com\r\nHack with us: https://roboflow.slab.com/public/posts/roboflow-hackathons-external-u478m1iz\r\nWork with us: roboflow.com/careers\r\n",
    "one_liner": "🖼️ Give your software the sense of sight.",
    "team_size": 50,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1598130074,
    "tags": [
      "Artificial Intelligence",
      "Developer Tools",
      "Machine Learning",
      "Computer Vision",
      "API"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2020",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/roboflow",
    "api": "https://yc-oss.github.io/api/batches/summer-2020/roboflow.json"
  },
  {
    "id": 21811,
    "name": "Hypermile",
    "slug": "hypermile",
    "former_names": [
      "Creation Labs"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b25c7b5a70e0fab68abb8837d04d772f89ba6623.png",
    "website": "https://hypermile.ai",
    "all_locations": "London, England, United Kingdom",
    "long_description": "Hypermile is on a mission to improve trucking efficiency, sustainability and safety by developing an AI driver assistance system 🚛 🌎🌱.\r\n\r\nToday, fuel is the main cost component for logistics operators, accounting for >1/3 of all operating costs. Driving behavior is a key factor affecting overall fuel consumption and can increase fuel use by up to 35%. However, current solutions are not cost effective, so logistics operators are constantly looking for new solutions. \r\n\r\nIn addition, logistics operators are under huge sustainability pressure, as Heavy Goods Vehicles (HGVs) are responsible for 16% of the UK's transport emissions but only 5% of the miles travelled. While electric vehicle sales for passenger vehicles are on the rise, the same can't be said for long-haul HGVs due to high initial cost and limited range, making it impractical for logistic purposes. \r\n\r\nWith this problem in mind, we aim to leverage the latest AI techniques to improve the fuel efficiency of diesel trucks today, and increase the range of zero-emission trucks of the future. \r\n\r\nOur product Hypermile Co-Pilot is a retrofittable AI cruise control for commercial vehicles focused on controlling the speed of the truck efficiently. We have trained the AI algorithms to learn the best techniques for saving fuel: anticipating how traffic flow will change, optimising speed based on the road gradient and maximizing vehicle coasting. As a result, we can reduce diesel consumption by 11% and extend the range of battery-electric vehicles by 15%. The long term vision is to incrementally build higher levels of autonomy with the next milestone being a Level-3 autonomous trucking solution. \r\n\r\nThe company was founded in May 2020 and raised a $1.5M pre-seed round in May 2021 from Y Combinator, Greg Brockman (CTO of OpenAI), Luc Vincent (former Executive VP of Autonomous Driving at Lyft Level 5) and others. We’ve received a number of R&D grants from Innovate UK, Department for Transport and Horizons 2020. We’re currently a team of 10 across Commercial, Product and Engineering (including 4. sub-teams cloud software, machine learning, automotive software and electronics).\r\n",
    "one_liner": "Driver co-pilot to make trucking more efficient",
    "team_size": 11,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1615568678,
    "tags": [
      "Autonomous Trucking",
      "Computer Vision",
      "Logistics",
      "Climate"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2020",
    "status": "Acquired",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United Kingdom",
      "Europe",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/hypermile",
    "api": "https://yc-oss.github.io/api/batches/summer-2020/hypermile.json"
  },
  {
    "id": 21962,
    "name": "Hellometer",
    "slug": "hellometer",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/a6ce1063846053edd4d35f8feec4badb3dc82dd8.png",
    "website": "https://hellometer.io/",
    "all_locations": "Los Angeles, CA, USA",
    "long_description": "Hellometer helps fast food owners' grow same store sales using security cameras to improve customer wait times.\r\n\r\nSpeed of service is fast food's core value proposition (it’s literally in the name) and owners currently don't have a reliable way to measure it. We show them when and where they have slowdowns and for every 7s they improve service times, owners see 1% increase in revenue. ",
    "one_liner": "Making fast food faster",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1598120897,
    "tags": [
      "SaaS",
      "Computer Vision",
      "B2B"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2020",
    "status": "Active",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/hellometer",
    "api": "https://yc-oss.github.io/api/batches/summer-2020/hellometer.json"
  },
  {
    "id": 22664,
    "name": "SBX Robotics",
    "slug": "sbx-robotics",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/511a67e1066575bd8304628248a6a9307430e18f.png",
    "website": "https://www.sbxrobotics.com/",
    "all_locations": "Toronto, ON, Canada",
    "long_description": "SBX Robotics generates synthetic data that teaches robots to see. We use simulation software to create training data 10x faster and cheaper than annotation services or in-house teams. \r\n\r\nInstead of being blocked on data, our clients send 25 images from their robot’s camera, and receive 25,000 perfectly labeled synthetic training images. SBX data is ready to be used by deep learning computer vision models. ",
    "one_liner": "Synthetic data for better vision.",
    "team_size": 5,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1616603536,
    "tags": [
      "Artificial Intelligence",
      "Machine Learning",
      "Robotics",
      "Computer Vision",
      "Data Engineering"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2021",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "Canada",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/sbx-robotics",
    "api": "https://yc-oss.github.io/api/batches/winter-2021/sbx-robotics.json"
  },
  {
    "id": 22743,
    "name": "Segments.ai",
    "slug": "segments-ai",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/ac88c08aefaf0753bc9d29d8d7ced656148b852c.png",
    "website": "https://segments.ai",
    "all_locations": "Brussels, Brussels, Belgium; Remote",
    "long_description": "[Segments.ai](http://segments.ai/) is helping robotics and automotive companies label their multi-sensor data for AI training and validation. Our platform enables customers to efficiently annotate their point cloud and image data, accelerating their path to autonomy.\r\n\r\nWe're a fast-growing, remote-first YC startup with a lean team and healthy runway. [Segments.ai](http://segments.ai/) is used by large organizations as well as innovative startups building the next generation of autonomous drones, delivery robots, self-driving cars, and more.",
    "one_liner": "Build better computer vision models by building better datasets",
    "team_size": 8,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1615300374,
    "tags": [
      "Deep Learning",
      "Developer Tools",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2021",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "Belgium",
      "Europe",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/segments-ai",
    "api": "https://yc-oss.github.io/api/batches/winter-2021/segments-ai.json"
  },
  {
    "id": 22744,
    "name": "Encord",
    "slug": "encord",
    "former_names": [
      "Cord Technologies",
      "Cord"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b0c0b8150edc64332f4d529343a9096db99002e1.png",
    "website": "https://encord.com",
    "all_locations": "London, England, United Kingdom",
    "long_description": "Encord is the leading data development platform for advanced vision and multimodal AI teams. We build tools and infrastructure to help the world's leading AI teams get their models into production faster - with data-centric model testing, human-centric workflow and annotation tools for labeling & RLHF, and data curation and management software. \r\n\r\nEncord is trusted by pioneering AI teams at Stanford Medicine, Mass General Brigham, Tractable, Viz AI, Iterative Health, the UHN, the Royal Navy, Veo, and many more global companies.",
    "one_liner": "The data development platform for AI teams",
    "team_size": 70,
    "industry": "B2B",
    "subindustry": "B2B -> Infrastructure",
    "launched_at": 1613768381,
    "tags": [
      "Artificial Intelligence",
      "Developer Tools",
      "Machine Learning",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2021",
    "status": "Active",
    "industries": [
      "B2B",
      "Infrastructure"
    ],
    "regions": [
      "United Kingdom",
      "Europe"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/encord",
    "api": "https://yc-oss.github.io/api/batches/winter-2021/encord.json"
  },
  {
    "id": 22752,
    "name": "ClipDrop",
    "slug": "clipdrop",
    "former_names": [
      "Init ML",
      "Clickdrop"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/3bfd4a654412f2405d3448ad846ed61f08074a04.png",
    "website": "https://clipdrop.co",
    "all_locations": "Paris, Île-de-France, France; Remote",
    "long_description": "ClipDrop is an app that turns regular mobile photos into professional product visuals.\r\n\r\nThanks to companies like Poshmark, Etsy and Ebay, there are now over 25M sellers who need great visuals for their shops but most of them don’t have access to a professional photographer or a design team. We replace all of this with our app available on mobile and desktop.\r\n\r\nWe’re a team of former Google, Facebook employees and Machine learning PhD’s and academic Professors. We believe that machine learning will bring professional photography and design to millions of businesses for a fraction of the cost.",
    "one_liner": "Turn regular mobile photos into professional product visuals",
    "team_size": 5,
    "industry": "Consumer",
    "subindustry": "Consumer -> Content",
    "launched_at": 1614841884,
    "tags": [
      "SaaS",
      "Computer Vision",
      "Design Tools"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2021",
    "status": "Acquired",
    "industries": [
      "Consumer",
      "Content"
    ],
    "regions": [
      "France",
      "Europe",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/clipdrop",
    "api": "https://yc-oss.github.io/api/batches/winter-2021/clipdrop.json"
  },
  {
    "id": 22969,
    "name": "LightTwist",
    "slug": "lighttwist",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/69063ba25c16af04c5fdb92fd680138cd0eaea3b.png",
    "website": "https://lighttwist.com",
    "all_locations": "Boulder, CO, USA; Remote",
    "long_description": "LightTwist is your virtual studio in the cloud. Record and stream video in a customizable virtual studio that you control from your browser.",
    "one_liner": "Record video in a photorealistic virtual studio all from your browser",
    "team_size": 4,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1616254222,
    "tags": [
      "Augmented Reality",
      "Computer Vision",
      "Design Tools"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2021",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/lighttwist",
    "api": "https://yc-oss.github.io/api/batches/winter-2021/lighttwist.json"
  },
  {
    "id": 24142,
    "name": "SnapCalorie",
    "slug": "snapcalorie",
    "former_names": [
      "CalorieSnap"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/8fb8d3ff1ae8ec164dd664632cc42c03b043c549.png",
    "website": "https://www.snapcalorie.com/",
    "all_locations": "New York, NY, USA; Washington, DC, USA",
    "long_description": "SnapCalorie is the world’s first app where you can take a photo of ANY meal and get an accurate calorie count.  It takes seconds to use and is more accurate than a trained nutritionist. The team previously co-founded Google Lens, Cloud Vision API, and published a CVPR paper demonstrating the first algorithm to outperform a professional nutritionist at calorie counting.",
    "one_liner": "Single photo nutrition tracking.",
    "team_size": 5,
    "industry": "Consumer",
    "subindustry": "Consumer",
    "launched_at": 1627329794,
    "tags": [
      "Computer Vision",
      "Fitness",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2021",
    "status": "Active",
    "industries": [
      "Consumer"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/snapcalorie",
    "api": "https://yc-oss.github.io/api/batches/summer-2021/snapcalorie.json"
  },
  {
    "id": 24383,
    "name": "Milky Way AI",
    "slug": "milky-way-ai",
    "former_names": [
      "Milky Way AI Pte.Ltd"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/2efe7f33198c252ca563c3f685bd5e290b4064d2.png",
    "website": "https://milkyway.ai/",
    "all_locations": "Singapore, Singapore; Remote",
    "long_description": "We help CPG brands to understand how their products are being displayed, priced and what are their competitors are doing across millions of physical stores in real time with our computer vision powered mobile app. \r\n\r\nEach year these brands spend $500 bn annually buying prime retail shelf space to influence customer purchasing decisions, but they have no easy way to audit it. \r\n\r\nOur mobile app reduces the time of these audits by 10x and cost by 3x.",
    "one_liner": "Mobile app for CPG brands to connect to millions of stores globally",
    "team_size": 5,
    "industry": "B2B",
    "subindustry": "B2B -> Retail",
    "launched_at": 1624944246,
    "tags": [
      "Artificial Intelligence",
      "SaaS",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2021",
    "status": "Inactive",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "Singapore",
      "Southeast Asia",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/milky-way-ai",
    "api": "https://yc-oss.github.io/api/batches/summer-2021/milky-way-ai.json"
  },
  {
    "id": 24551,
    "name": "Mach9",
    "slug": "mach9",
    "former_names": [
      "Mach9 Robotics"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/232339d6edde0605ea880f4aaef47c45acf14848.png",
    "website": "https://www.mach9.ai/",
    "all_locations": "San Francisco, CA, USA; Pittsburgh, PA, USA",
    "long_description": "Mach9 is at the forefront of leveraging advanced machine learning and computer vision techniques to transform geospatial data into actionable insights for urban development and infrastructure management. Our cutting-edge technology automates the detection and analysis of key urban features, aiding in the planning and maintenance of transportation networks.",
    "one_liner": "The Fastest Tool for Automating Geospatial Production",
    "team_size": 15,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1628526474,
    "tags": [
      "Machine Learning",
      "Computer Vision",
      "Infrastructure",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2021",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/mach9",
    "api": "https://yc-oss.github.io/api/batches/summer-2021/mach9.json"
  },
  {
    "id": 24567,
    "name": "Tenyks",
    "slug": "tenyks",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/7006298209ca0e4b566665242aadbc44f58b1d59.png",
    "website": "http://tenyks.ai/",
    "all_locations": "Cambridge, England, United Kingdom; Remote",
    "long_description": "Tenyks (YC S21) is a Cambridge University spin-out building the World's Most Versatile Visual Intelligence Platform—think Snowflake for Vision or GPT for Video.\r\n\r\nProblem: Companies today collect oceans of visual data (from cameras, drones, and satellites), but struggle to extract actionable insights. Current solutions rely heavily on manual analysis by call centres in locations like the Philippines or AI platforms narrowly focused on security rather than deeper operational insights. This leaves critical improvements in efficiency, customer satisfaction, and revenue growth unrealised.\r\n\r\nSolution: Tenyks unlocks unprecedented insights by applying advanced multimodal Vision-Language Models (VLMs) capable of comprehensive video summarisation, retrieval, and visual question-answering. These VLMs are seamlessly combined with specialised analytics for emotion detection, activity recognition, object tracking, and even gait analysis. Our platform transforms ordinary visual footage into extraordinary operational intelligence.\r\n\r\nInitial Focus: Starting with Quick Service Restaurants (QSRs), we enable operations leaders to instantly understand customer flow, kitchen efficiency, staff productivity, and quality of service using their existing security camera footage—turning previously inaccessible data into direct operational improvements and clear financial ROI. For instance, insights from Tenyks can accelerate the speed of service significantly; even a 1-second improvement in service speed could generate $30,000 additional annual revenue per restaurant. For a multi-unit owner of 100 restaurants, that's an additional $3 million per year.\r\n\r\nTraction: We've recently secured our first Fortune 500 customer, joining other major enterprises, global system integrators, and high-growth startups trusting Tenyks for powerful, data-driven decision-making.\r\n\r\nWhy Tenyks: Our patented technology originates from the founders' PhD research at Cambridge University. Previously, we helped world-leading teams scale high-performing Vision AI in production. \r\n\r\nRecognition: Recognised as a Rising Star in Gen AI by Sifted, Best Product of the Year by Vision AI Alliance, and Company of the Year by Cambridge University (previously awarded to DeepMind).",
    "one_liner": "The World's Most Versatile Video Answering Engine ",
    "team_size": 11,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1630087785,
    "tags": [
      "Artificial Intelligence",
      "Computer Vision",
      "Video",
      "AI",
      "AI Assistant"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2021",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United Kingdom",
      "Europe",
      "Remote",
      "Fully Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/tenyks",
    "api": "https://yc-oss.github.io/api/batches/summer-2021/tenyks.json"
  },
  {
    "id": 26254,
    "name": "Eventual",
    "slug": "eventual",
    "former_names": [
      "Eventual Computing"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/f429c16ee024d738c1b758e7c2d0ca5d811f204b.png",
    "website": "https://www.daft.ai/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Every breakthrough AI application, from foundation models to autonomous vehicles, relies on processing massive volumes of images, video, and complex data. But today’s data platforms (like Databricks and Snowflake) are built on top of tools made for spreadsheet-like analytics, not the petabytes of multimodal data that power AI. As a result, teams waste months on brittle infrastructure instead of conducting research and building their core product.\r\n\r\nEventual was founded in 2022 to solve this. Our mission is to make querying any kind of data, images, video, audio, text, as intuitive as working with tables, and powerful enough to scale to production workloads. Our open-source engine, Daft, is purpose-built for real-world AI systems: coordinating with external APIs, managing GPU clusters, and handling failures that traditional engines can’t. Daft already powers critical workloads at companies like Amazon, Mobileye, Together AI, and CloudKitchens.\r\n\r\nWe’ve assembled a world-class team from Databricks, AWS, Nvidia, Pinecone, GitHub Copilot, Tesla, and more, quadrupling our size within a year. With backing from Y Combinator, Caffeinated Capital, Array.vc, and top angels from the co-founders of Databricks and Perplexity, we’re looking to double the team now. Join us—Eventual is just getting started.\r\n\r\nPlease note we are looking for someone who is willing and able to come into our San Francisco office in the Mission district 4 days / week.",
    "one_liner": "Building the AI data engine for any modality and scale",
    "team_size": 18,
    "industry": "B2B",
    "subindustry": "B2B -> Infrastructure",
    "launched_at": 1648154182,
    "tags": [
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2022",
    "status": "Active",
    "industries": [
      "B2B",
      "Infrastructure"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/eventual",
    "api": "https://yc-oss.github.io/api/batches/winter-2022/eventual.json"
  },
  {
    "id": 26718,
    "name": "Cerrion",
    "slug": "cerrion",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/a2cfaa4757206398a9d1678a216905dc2a248f11.png",
    "website": "https://www.cerrion.com/",
    "all_locations": "Zürich, ZH, Switzerland",
    "long_description": "Cerrion helps manufacturers automatically detect, understand and eliminate problems on their production lines using video-based Computer Vision. Our AI leverages standard CCTV cameras and learns how a manufacturing process looks like when things are going well and can automatically detect and track problems in real-time.\r\n\r\nFor example, one of our customers, a Pepsi supplier producing 500 bottles per minute now automatically detects and reacts to a fallen bottle before it starts blocking their production line. ",
    "one_liner": "Video AI to automatically detect and respond to production line…",
    "team_size": 9,
    "industry": "Industrials",
    "subindustry": "Industrials",
    "launched_at": 1659519771,
    "tags": [
      "Deep Learning",
      "Computer Vision",
      "Video",
      "Manufacturing",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2022",
    "status": "Active",
    "industries": [
      "Industrials"
    ],
    "regions": [
      "Switzerland",
      "Europe"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/cerrion",
    "api": "https://yc-oss.github.io/api/batches/summer-2022/cerrion.json"
  },
  {
    "id": 26802,
    "name": "Apply Design",
    "slug": "apply-design",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/731fd6f22634f935a03484945b5b569dae8c8ed9.png",
    "website": "http://www.applydesign.io",
    "all_locations": "Tel Aviv-Yafo, Tel Aviv District, Israel",
    "long_description": "Apply Design is a leading AI-powered virtual staging app that empowers real estate professionals to showcase the full potential of their properties to prospective buyers, helping them sell homes faster and for higher prices. \r\n\r\nWe virtually stage over 10,000 properties monthly, transforming images of vacant or outdated spaces into fully furnished, captivating property photos. Our proprietary AI-powered software is the only solution capable of generating photorealistic designs in one click while also enabling instant customization of any detail with complete control.\r\n\r\nThis is a $10B market opportunity, given the 50M properties sold or rented annually in North America and Europe alone. ",
    "one_liner": "Helping realtors showcase the full potential of their properties",
    "team_size": 9,
    "industry": "Real Estate and Construction",
    "subindustry": "Real Estate and Construction",
    "launched_at": 1655775419,
    "tags": [
      "Generative AI",
      "SaaS",
      "Computer Vision",
      "Proptech",
      "E-commerce"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2022",
    "status": "Active",
    "industries": [
      "Real Estate and Construction"
    ],
    "regions": [
      "Israel",
      "Middle East and North Africa",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/apply-design",
    "api": "https://yc-oss.github.io/api/batches/summer-2022/apply-design.json"
  },
  {
    "id": 27221,
    "name": "CAPSULE",
    "slug": "capsule",
    "former_names": [
      "Dryftwell",
      "GLIMPSE"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/19f195e9a25d1cff1f914f65ceb3e7458c6d52b9.png",
    "website": "https://www.shopcapsule.ai/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "CAPSULE is a mobile app that makes it easy to save and buy the things you find on any social media platform. Just snap a screenshot of anything you like, from any platform, and we search the entire internet to instantly give you shoppable links. \r\n\r\nInstead of searching hundreds of websites and sifting through thousands of products on your own, CAPSULE lets you find inspiration from anywhere and uses advanced machine learning to return results that feel like magic. ",
    "one_liner": "Buy anything you find on social media",
    "team_size": 4,
    "industry": "Consumer",
    "subindustry": "Consumer -> Apparel and Cosmetics",
    "launched_at": 1661989948,
    "tags": [
      "Artificial Intelligence",
      "Generative AI",
      "Machine Learning",
      "Computer Vision",
      "E-commerce"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2022",
    "status": "Inactive",
    "industries": [
      "Consumer",
      "Apparel and Cosmetics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/capsule",
    "api": "https://yc-oss.github.io/api/batches/summer-2022/capsule.json"
  },
  {
    "id": 27828,
    "name": "Scanbase",
    "slug": "scanbase",
    "former_names": [
      "Scanbase, Inc."
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/2982f68c8c82ccb0dcb8909ae50c7cdbbdcd9b70.png",
    "website": "https://www.scanbase.com",
    "all_locations": "Los Angeles, CA, USA",
    "long_description": "Scanbase makes it easy for medical companies to convert photos of rapid diagnostic tests into results. We do this by providing a simple API that any medical company can access.\r\n",
    "one_liner": "The API for Diagnostic Test Analysis (COVID-19, FLU, RSV, STD,…",
    "team_size": 10,
    "industry": "Healthcare",
    "subindustry": "Healthcare -> Diagnostics",
    "launched_at": 1670991822,
    "tags": [
      "Artificial Intelligence",
      "Machine Learning",
      "Computer Vision",
      "Health Tech",
      "Telemedicine"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2023",
    "status": "Active",
    "industries": [
      "Healthcare",
      "Diagnostics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/scanbase",
    "api": "https://yc-oss.github.io/api/batches/winter-2023/scanbase.json"
  },
  {
    "id": 27860,
    "name": "Dream3D",
    "slug": "dream3d",
    "former_names": [
      "MettaSpace"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/dc5c128914787f1ad09c34983b9c40c1200da598.png",
    "website": "https://dream3d.com",
    "all_locations": "New York, NY, USA",
    "long_description": "Dream3D builds generative models to simulate and emulate worlds, real and imagined.",
    "one_liner": "Generative AI Worlds",
    "team_size": 3,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1677865645,
    "tags": [
      "Generative AI",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2023",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/dream3d",
    "api": "https://yc-oss.github.io/api/batches/winter-2023/dream3d.json"
  },
  {
    "id": 28114,
    "name": "rex.fit",
    "slug": "rex-fit",
    "former_names": [
      "Babylon AI",
      "BabylonAI"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/c618208d2cb852eeff16409fb7e787701c395b91.png",
    "website": "https://www.rex.fit",
    "all_locations": "Zürich, ZH, Switzerland",
    "long_description": "The DROP by Rex.Fit is an AI wearable camera that automates nutrition tracking using computer vision. It has garnered more than 93k USD in preorders (~450 units) since its launch last month. The nutrition estimation and recommendation tech behind the DROP is already integrated as an API for fitness chains, generating hundreds of thousands of dollars in yearly revenue for them. The DROP is built by brothers, sports nutritionists and computer vision engineers from the Swiss Federal Institute of Technology (ETH Zurich).",
    "one_liner": "Automating nutrition tracking.",
    "team_size": 2,
    "industry": "Consumer",
    "subindustry": "Consumer",
    "launched_at": 1674733041,
    "tags": [
      "Artificial Intelligence",
      "Hard Tech",
      "Computer Vision",
      "Consumer Health Services",
      "Fitness"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2023",
    "status": "Active",
    "industries": [
      "Consumer"
    ],
    "regions": [
      "Switzerland",
      "Europe"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/rex-fit",
    "api": "https://yc-oss.github.io/api/batches/winter-2023/rex-fit.json"
  },
  {
    "id": 28859,
    "name": "MICSI",
    "slug": "micsi",
    "former_names": [
      "MICSI (Microstructure Imaging, Inc)"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/29d35560d45b90c5227b12877556942576e43627.png",
    "website": "https://www.micsi.co/",
    "all_locations": "New York, NY, USA",
    "long_description": "MICSI is introducing AI software that doubles resolution and halves scan time. This breakthrough enables imaging centers to significantly enhance their capacity and patient throughput, potentially saving countless lives and generating an additional $2 million of revenue per MRI scanner. Our initial offering serves as a stepping stone toward the company’s larger vision of transforming the MRI into a truly quantitative instrument that is capable of providing highly reproducible data for more accurate diagnoses and patient management. ",
    "one_liner": "Higher resolution MRI with faster scan times.",
    "team_size": 2,
    "industry": "Healthcare",
    "subindustry": "Healthcare -> Diagnostics",
    "launched_at": 1687381964,
    "tags": [
      "Computer Vision",
      "Medical Devices",
      "Healthcare"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2023",
    "status": "Active",
    "industries": [
      "Healthcare",
      "Diagnostics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/micsi",
    "api": "https://yc-oss.github.io/api/batches/summer-2023/micsi.json"
  },
  {
    "id": 28867,
    "name": "Shasta Health",
    "slug": "shasta-health",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/d0ddbae01a1bda2827881248dc2c26ab87f27982.png",
    "website": "https://www.shasta.health",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Shasta Health helps physical therapists go independent and earn 3x more per visit. Our AI agents automatically source patients, handle scheduling, and bill insurance, so PTs can focus on providing great care.\r\n\r\nPatients get a concierge in-home appointment that's fully covered by insurance. Book an appointment today at www.shasta.health",
    "one_liner": "Get physical therapy at home, covered by insurance",
    "team_size": 2,
    "industry": "Healthcare",
    "subindustry": "Healthcare -> Healthcare Services",
    "launched_at": 1690927737,
    "tags": [
      "Artificial Intelligence",
      "Generative AI",
      "Computer Vision",
      "Digital Health",
      "Healthcare"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2023",
    "status": "Active",
    "industries": [
      "Healthcare",
      "Healthcare Services"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/shasta-health",
    "api": "https://yc-oss.github.io/api/batches/summer-2023/shasta-health.json"
  },
  {
    "id": 28891,
    "name": "Cleancard",
    "slug": "cleancard",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/b2b82979e8cd1a007de394d4f1a3a8e665968d02.png",
    "website": "https://www.cleancard.bio",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "We are combining synthetic biology and artificial intelligence to make cancer detection as easy as a pregnancy test. Cleancard's mission is to bring lab-grade diagnostics into the comfort of your home. Our novel method enables robust diagnostics and biomarker tracking from the urine. We are currently developing fully at-home, 30-minute tests for cancer using this methodology. We are constantly expanding the number of conditions we can detect from a single sample with our platform technology.",
    "one_liner": "Making cancer detection as easy as a pregnancy test",
    "team_size": 12,
    "industry": "Healthcare",
    "subindustry": "Healthcare -> Diagnostics",
    "launched_at": 1691571179,
    "tags": [
      "Artificial Intelligence",
      "Computer Vision",
      "Biotech",
      "Healthcare",
      "Diagnostics"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2023",
    "status": "Active",
    "industries": [
      "Healthcare",
      "Diagnostics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/cleancard",
    "api": "https://yc-oss.github.io/api/batches/summer-2023/cleancard.json"
  },
  {
    "id": 29396,
    "name": "edgetrace",
    "slug": "edgetrace",
    "former_names": [
      "EdgeTrace AI"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/a192e9ed03a7a8ac3d8044e52da7d6e1bda15b2a.png",
    "website": "https://edgetrace.ai",
    "all_locations": "",
    "long_description": "High-precision video search for mission critical applications",
    "one_liner": "Find the moments that matter",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "Unspecified",
    "launched_at": 1710460608,
    "tags": [
      "Computer Vision",
      "B2B",
      "Video",
      "API",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2024",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/edgetrace",
    "api": "https://yc-oss.github.io/api/batches/winter-2024/edgetrace.json"
  },
  {
    "id": 29442,
    "name": "Ocular AI",
    "slug": "ocular-ai",
    "former_names": [
      "AutoflowAI (Zapier for AI Copilots)"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/2e20f659338993dfe61925632a05952fe44797ed.png",
    "website": "https://useocular.com",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Ocular AI is the data annotation engine for Generative AI, Computer Vision, and Enterprise AI models.\r\n\r\nWe help you transform unstructured, multi-modal data into golden datasets to power generative AI, frontier models, and computer vision.   \r\n\r\nOcular Foundry is the most intuitive, data-centric, and fastest platform that lets you label, annotate, version, and deploy your data for training models. It also orchestrates your annotation jobs, improving collaboration with members and annotators.   \r\n\r\nWith Ocular Bolt, shift from humans in the loop to experts in the loop to supercharge your data labeling and annotation projects. Our global expert workforce ensures fast, accurate results—no matter the scale or complexity of your data.  \r\n\r\nCompanies spend huge amounts on training data, but Foundry and Bolt are AI-native tools that lower costs, reduce manual effort, and accelerate high-quality data collection. We’re replacing outdated, clunky, and expensive data software!",
    "one_liner": "AI-Native Data Engine for LLMs, Computer Vision, & Enterprise AI",
    "team_size": 5,
    "industry": "B2B",
    "subindustry": "Unspecified",
    "launched_at": 1706216304,
    "tags": [
      "Developer Tools",
      "Machine Learning",
      "Computer Vision",
      "Data Engineering",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2024",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/ocular-ai",
    "api": "https://yc-oss.github.io/api/batches/winter-2024/ocular-ai.json"
  },
  {
    "id": 29447,
    "name": "Deepnight",
    "slug": "deepnight",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/419c6b136773af60713e2a4301554b4ef1bbd8a9.png",
    "website": "https://www.deepnight.ai/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "DeepNight is building the next generation of night vision with AI.",
    "one_liner": "Building The Next Generation of Night Vision Devices",
    "team_size": 8,
    "industry": "Government",
    "subindustry": "Unspecified",
    "launched_at": 1709629638,
    "tags": [
      "Artificial Intelligence",
      "Computer Vision"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2024",
    "status": "Active",
    "industries": [
      "Government"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/deepnight",
    "api": "https://yc-oss.github.io/api/batches/winter-2024/deepnight.json"
  },
  {
    "id": 29503,
    "name": "Dragoneye",
    "slug": "dragoneye",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/354a00433e0332ff17869b4c08d6ee8d10b8a232.png",
    "website": "https://dragoneye.ai/",
    "all_locations": "New York, NY, USA",
    "long_description": "Dragoneye helps devs build powerful apps and features that use images and videos. With our cutting-edge AI tech, folks can recognize things in the world with high accuracy and deep granularity - more than 13K classes - right out of the box. No more arduous process of annotating any training data or doing any machine learning work themselves.\r\n\r\nTry out our demo today at https://dashboard.dragoneye.ai/!",
    "one_liner": "More detailed object recognition than Google and Amazon",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "Unspecified",
    "launched_at": 1705986923,
    "tags": [
      "Artificial Intelligence",
      "Developer Tools",
      "Computer Vision",
      "ML"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2024",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/dragoneye",
    "api": "https://yc-oss.github.io/api/batches/winter-2024/dragoneye.json"
  },
  {
    "id": 29635,
    "name": "DigitalCarbon",
    "slug": "digitalcarbon",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/5cd96189d0726eb13cddf2279ecddbb8f1d37895.png",
    "website": "https://www.digitalcarbon.ai",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Digitalcarbon transforms ordinary images and videos into interactive, photorealistic 3D environments. Our technology can take photos from any device and render 3D scenes at more than 100 frames per second on everyday devices. \r\n\r\nThe founders were the first and second hires at a previous YC company AssemblyAI, and have more than 8 years of experience building AI models. \r\n\r\nCreating immersive 3D experiences typically requires complex equipment and suffers from slow rendering speeds. This has limited the adoption of 3D technology across various industries. Digitalcarbon fixes that, eliminating the need for specialized equipment and dramatically accelerating the rendering process.\r\n\r\nOur technology enables applications across various industries:\r\n* Real estate: Creating virtual property tours that feel remarkably lifelike\r\n* E-commerce: Providing interactive 3D product visualizations to boost consumer experience\r\n* Tourism: Helping tourist businesses attract more travelers with immersive virtual previews\r\n* Drone mapping and inspection: Enhancing aerial surveys and structural assessments with detailed 3D models\r\n\r\nThink Unreal Engine meets Matterport with no hardware, but faster, editable, and more accessible for businesses of all sizes.",
    "one_liner": "Transform Images And Videos Into Immersive 3D With AI",
    "team_size": 0,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1725300975,
    "tags": [
      "Computer Vision",
      "Real Estate",
      "B2B",
      "E-commerce",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2024",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/digitalcarbon",
    "api": "https://yc-oss.github.io/api/batches/summer-2024/digitalcarbon.json"
  },
  {
    "id": 29819,
    "name": "Weel",
    "slug": "weel",
    "former_names": [
      "Vizia"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/22dac63897681e1a31dc26b877ee786266ae0bff.png",
    "website": "https://weel.live/",
    "all_locations": "New York, NY, USA",
    "long_description": "Weel is the next-generation all-in-one driver co-pilot that redefines your driving experience by turning your smartphone into a complete safety and navigation hub. Our free app offers a built-in dashcam with easy video sharing, a smart navigation system, and advanced AI features—such as augmented reality navigation and ADAS—that reduce your risk by up to 30%. Say goodbye to expensive dashcams and complex setups – with Weel, you get complete driving safety and guidance in one free smartphone app.",
    "one_liner": "GPS & dashcam smartphone app",
    "team_size": 4,
    "industry": "Consumer",
    "subindustry": "B2B -> Supply Chain and Logistics",
    "launched_at": 1741795332,
    "tags": [
      "Augmented Reality",
      "Computer Vision",
      "Navigation",
      "Mobility",
      "Automotive"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2024",
    "status": "Active",
    "industries": [
      "Consumer",
      "Transportation Services"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/weel",
    "api": "https://yc-oss.github.io/api/batches/summer-2024/weel.json"
  },
  {
    "id": 29823,
    "name": "autarc",
    "slug": "autarc",
    "former_names": [
      "autarc GmbH"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/c6f422aa332e520cce9d631b8dfbcdfb14375c6e.png",
    "website": "https://www.autarc.energy/en",
    "all_locations": "Berlin, Berlin, Germany",
    "long_description": "With autarc we are building the OS for Europe's One-Stop Energy Installers.\r\n\r\nThe problem: Energy installers are eager to expand their deployment of heat pump and photovoltaic systems, yet they are constrained by inefficient sales, planning, and installation processes.\r\n\r\nThe solution: Our B2B software integrates CRM, planning, and design tools into a unified platform. This enables SMB installers to drastically cut down the pre-installation phase of home energy projects—from several weeks to just minutes. By leveraging LiDAR for spatial analysis, computer vision for automated assessment, and AI for system recommendations, we streamline the entire workflow. This results in a time reduction of up to 90%, enabling installers to confidently transition to and scale up sustainable home energy solutions.",
    "one_liner": "autarc is the OS for Europe's One-Stop Energy Installers",
    "team_size": 30,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1720714870,
    "tags": [
      "Lidar",
      "Computer Vision",
      "B2B",
      "Climate",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2024",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "Germany",
      "Europe",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/autarc",
    "api": "https://yc-oss.github.io/api/batches/summer-2024/autarc.json"
  },
  {
    "id": 29847,
    "name": "Bucket Robotics",
    "slug": "bucket-robotics",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/55cc697d9f14eca5a5d45772ac14d97a83df16ae.png",
    "website": "https://bucket.bot",
    "all_locations": "",
    "long_description": "Bucket Robotics is making defect detection faster, easier, and more deployable — starting with the 250M lbs of plastic wasted annually in U.S. manufacturing.\r\n\r\nOur platform turns CAD files into defect detectors. We generate synthetic, photorealistic training data to help factories catch flaws before they ship. No manual labeling, no real defects required. Our models deploy to edge hardware and integrate easily into existing automation stacks.\r\n\r\nWe come from the self-driving world (Argo AI, Uber ATG, Stack AV), where we built reliable perception in high-noise, real-world environments. We're applying that experience to manufacturing: robust sensing, user-friendly interfaces, and fast iteration cycles.\r\n\r\nManufacturers hesitate to adopt new sensing due to data concerns, integration risk, and poor UX. We’ve handled petabytes of regulated autonomy data — and built systems that earn trust.\r\n\r\nLegacy vendors like Keyence and FLIR offer hardware-centric tools with bloated pricing and outdated software. We’re building the opposite: flexible, modern tools that engineers want to use.\r\n\r\nManufacturing is in the middle of a $700B automation wave across North America. Bucket Robotics is building the quality control infrastructure to match.",
    "one_liner": "Defect detection for manufacturing built from CAD and synthetic data.",
    "team_size": 2,
    "industry": "Industrials",
    "subindustry": "Industrials -> Manufacturing and Robotics",
    "launched_at": 1719001491,
    "tags": [
      "Robotic Process Automation",
      "Robotics",
      "Computer Vision",
      "Manufacturing"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Summer 2024",
    "status": "Active",
    "industries": [
      "Industrials",
      "Manufacturing and Robotics"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/bucket-robotics",
    "api": "https://yc-oss.github.io/api/batches/summer-2024/bucket-robotics.json"
  },
  {
    "id": 30229,
    "name": "Maive",
    "slug": "maive",
    "former_names": [
      "MAIVE (Manufacturing AI Vision Engine)"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/c8c2773604bbaf5a32094fbcb757b92f9d29a32e.png",
    "website": "https://maive.ai",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Maive automates aerospace compliance paperwork required on the manufacturing shop floor. We use cameras and AI to automatically fill federally-required paperwork, reducing the risk of companies being unable to sell their products and increasing factory throughput.\r\n\r\nUsers have told us the paperwork required for the F-35 fighter jet weighs more than the jet itself! The government requires a record for each of the 1.5 million parts in the jet, including what shop-floor workers do to each part and when they do it.\r\n\r\nAutomating paperwork by interpreting human actions with cameras is hard. Doing this at the edge and inside secure aerospace environments is harder. We fine-tune the latest vision language models to solve what was previously impossible.\r\n\r\nManufacturers lose millions when compliance paperwork has errors because it can freeze their ability to sell the product for months. Leaving this task to shop floor workers is both incredibly risky to the company and tedious for the employees. \r\n\r\nCompliance paperwork is just the beginning. We want to propel American manufacturing into the AI era. America is facing a serious problem: there’s $400B being invested to onshore manufacturing, but there’s simultaneously a projected 15% gap in workers needed due to an aging workforce. We’re on a mission to solve this by building the first AI native software for the shop floor. Our vision is to intelligently connect people, robots, and data to 10x today’s manufacturing capacity.",
    "one_liner": "Visual AI for factories",
    "team_size": 2,
    "industry": "Industrials",
    "subindustry": "Industrials -> Manufacturing and Robotics",
    "launched_at": 1740103642,
    "tags": [
      "Artificial Intelligence",
      "Warehouse Management Tech",
      "Computer Vision",
      "Compliance",
      "Aerospace"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2025",
    "status": "Active",
    "industries": [
      "Industrials",
      "Manufacturing and Robotics"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/maive",
    "api": "https://yc-oss.github.io/api/batches/winter-2025/maive.json"
  },
  {
    "id": 30251,
    "name": "Mecha Health",
    "slug": "mecha-health",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/e851087b2c25e5bd175d39d8631791d74e04ebb1.png",
    "website": "https://www.mecha-health.ai/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Mecha Health builds foundation models to automate x-ray analysis for radiologists. We take medical images and process them using proprietary models to produce accurate draft medical reports. Our first model was built in less than two months, and beat Microsoft, Google, and OpenAI on clinical accuracy metrics. On top of that, it’s two orders of magnitude smaller and trained with a quarter of the data.\r\n\r\nWe are partnering with the largest privately owned radiology practice in the US and a multinational tele-radiology company to provide them with their own foundation model, enabling their radiologists to go from reading 1 scan per hour to 1 scan every 5 minutes. By charging on a per scan basis, x-ray report generation represents a 40B+ market opportunity. ",
    "one_liner": "Foundation models to automate x-ray analysis for radiologists",
    "team_size": 4,
    "industry": "Healthcare",
    "subindustry": "Healthcare",
    "launched_at": 1737153298,
    "tags": [
      "Artificial Intelligence",
      "Machine Learning",
      "Computer Vision",
      "Health Tech",
      "Healthcare"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2025",
    "status": "Active",
    "industries": [
      "Healthcare"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/mecha-health",
    "api": "https://yc-oss.github.io/api/batches/winter-2025/mecha-health.json"
  },
  {
    "id": 30284,
    "name": "Exla",
    "slug": "exla",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/94cd00784e37842fc455ee2fd7b22d487b0693cf.png",
    "website": "https://exla.ai/",
    "all_locations": "",
    "long_description": "Exla aggressively quantizes AI models to minimize memory usage and maximize inference speed. Whether you're deploying LLMs, VLMs, VLAs, or custom models, Exla reduces memory footprint by up to 80% and accelerates inference by 3–20x - all with just a few lines of code.\r\n\r\nhttps://cal.com/exla-ai/schedule",
    "one_liner": "An SDK to run transformer models anywhere",
    "team_size": 0,
    "industry": "B2B",
    "subindustry": "B2B -> Engineering, Product and Design",
    "launched_at": 1740012412,
    "tags": [
      "Edge Computing Semiconductors",
      "Computer Vision",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Engineering, Product and Design"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/exla",
    "api": "https://yc-oss.github.io/api/batches/winter-2025/exla.json"
  },
  {
    "id": 30315,
    "name": "Optifye.ai",
    "slug": "optifye-ai",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/d86ffdce2296389239f29bc23023bc7867815208.png",
    "website": "https://www.optifye.ai",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Optifye.ai does AI performance monitoring for factory workers\r\n\r\nWe place cameras in factories and use vision AI to tell supervisors who's working and who's not in real time. \r\n\r\nThe shop floor has historically been a black box. With Optifye, manufacturing companies can now accurately measure worker output and boost efficiency!",
    "one_liner": "AI performance monitoring for factory workers",
    "team_size": 8,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1739567184,
    "tags": [
      "Hard Tech",
      "Computer Vision",
      "Manufacturing"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": true,
    "nonprofit": false,
    "batch": "Winter 2025",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/optifye-ai",
    "api": "https://yc-oss.github.io/api/batches/winter-2025/optifye-ai.json"
  },
  {
    "id": 30317,
    "name": "Permitify",
    "slug": "permitify",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/e0fb1e449f45c8f9ca33c6947992cac6af3e8c0f.png",
    "website": "https://permitify.com",
    "all_locations": "",
    "long_description": "City building departments are understaffed and overworked. Meanwhile, builders lobby to remove power from building departments. Because building departments are usually the only profitable/self-sustaining branch of a local government, this is problematic. Permitify allows city build-plan reviewers to 10x their productivity covering the labor shortage, reducing the time required to issue a building permit, and allowing the city government's only profitable branch to stay intact.",
    "one_liner": "AI co-pilot for building plan review and building code compliance",
    "team_size": 2,
    "industry": "Real Estate and Construction",
    "subindustry": "Real Estate and Construction -> Construction",
    "launched_at": 1737593819,
    "tags": [
      "Generative AI",
      "GovTech",
      "Computer Vision",
      "Construction"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Winter 2025",
    "status": "Active",
    "industries": [
      "Real Estate and Construction",
      "Construction"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/permitify",
    "api": "https://yc-oss.github.io/api/batches/winter-2025/permitify.json"
  },
  {
    "id": 30446,
    "name": "Kirana AI",
    "slug": "kirana-ai",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/6bc9cf5c0f4cd5c6141c30f400757b42039051c6.png",
    "website": "https://www.kirana-ai.com",
    "all_locations": "New York, NY, USA",
    "long_description": "Kirana AI is building the first full-stack AI store manager.\r\n\r\nWith 100 years of family experience owning and operating grocery stores, we are starting there to prove our impact.\r\n\r\nOur first product utilizes an on-premise GPU that monitors the store 24/7, scans for theft, looks for workplace health and safety issues, and optimizes customer service. \r\n\r\nWith future POS/ordering data integrations, our manager will automate many of the day-to-day tasks of running a store, such as ordering, pricing, assortment, and delegating.",
    "one_liner": "AI manager for physical stores",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1747354989,
    "tags": [
      "Grocery",
      "Computer Vision",
      "Retail",
      "AI"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Spring 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Retail"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/kirana-ai",
    "api": "https://yc-oss.github.io/api/batches/spring-2025/kirana-ai.json"
  },
  {
    "id": 30542,
    "name": "LineWise",
    "slug": "linewise",
    "former_names": [
      "Comply Genie",
      "Vision Nexus"
    ],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/52b288a75cbc24bbab29ace4752b6453e7db35bf.png",
    "website": "https://www.linewise.io/",
    "all_locations": "",
    "long_description": "LineWise is building an AI assistant for manufacturing teams to get their line back up and running.\r\n\r\nWhen a line goes down, it can take hours to identify the problem. Engineers and technicians scramble, chasing PLC data and logs, flipping through manuals and troubleshooting guides, while production stalls.\r\n\r\nLineWise connects siloed data from PLCs, maintenance logs, and machine manuals to triage potential causes for the issue at hand. Once the issue is resolved, LineWise will remember everything for the next time and advocate preventative actions.",
    "one_liner": "AI Engineer to troubleshoot manufacturing line issues",
    "team_size": 5,
    "industry": "B2B",
    "subindustry": "B2B -> Operations",
    "launched_at": 1743036496,
    "tags": [
      "Generative AI",
      "Computer Vision",
      "Manufacturing",
      "Operations"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Spring 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Operations"
    ],
    "regions": [
      "Unspecified"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": true,
    "url": "https://www.ycombinator.com/companies/linewise",
    "api": "https://yc-oss.github.io/api/batches/spring-2025/linewise.json"
  },
  {
    "id": 30664,
    "name": "Kestroll",
    "slug": "kestroll",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/146dcc3d13f9a26c2300485534fada61ffbc8c0f.png",
    "website": "https://www.kestroll.com/",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Kestroll is the AI-powered media asset management platform.\r\n\r\nKestroll automatically ingests, labels, and organizes all of your company's media assets (videos, photos, audio files, etc.) and provides a central interface for the entire organization to access and distribute content.\r\n\r\nKestroll eliminates the laborious labeling process and provides easy content access for the entire organization, without the clunky interfaces and long learning curves of traditional MAMs.\r\n\r\nThe days of filtering through someone else's tags are past. With Kestroll, anyone in the organization can search in everyday language, based on visual cues, abstract concepts, creative intent, and more, without the burden of manual labeling. ",
    "one_liner": "AI media asset management",
    "team_size": 2,
    "industry": "B2B",
    "subindustry": "B2B -> Operations",
    "launched_at": 1751838348,
    "tags": [
      "Artificial Intelligence",
      "Computer Vision",
      "Video",
      "Automation"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2025",
    "status": "Active",
    "industries": [
      "B2B",
      "Operations"
    ],
    "regions": [
      "United States of America",
      "America / Canada"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/kestroll",
    "api": "https://yc-oss.github.io/api/batches/summer-2025/kestroll.json"
  },
  {
    "id": 30769,
    "name": "Juxta",
    "slug": "juxta",
    "former_names": [],
    "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/0e2406b819c520b6b5c6f58e45423c720bf0661d.png",
    "website": "https://usejuxta.org",
    "all_locations": "San Francisco, CA, USA",
    "long_description": "Juxta is creating the first Universal Positioning System (UPS) — a GPS alternative that can monitor movement anywhere on earth with no new hardware, minimal internet connection, and remote deployment. Using custom machine learning models and a first-of-its-kind synthetic fingerprinting technology, Juxta can make any indoor, outdoor, or underground space location-aware in minutes for a fraction of the cost of any other geospatial technology.\r\n\r\nJuxta's UPS can be leveraged across industries — from securely tracking soldiers in combat zones to providing offline positioning for robots to offering asset tracking in warehouses and ports around the globe.",
    "one_liner": "Building a GPS alternative 100x more powerful with no hardware needed.",
    "team_size": null,
    "industry": "B2B",
    "subindustry": "B2B",
    "launched_at": 1751908614,
    "tags": [
      "Indoor Mapping",
      "Computer Vision",
      "ML"
    ],
    "tags_highlighted": [],
    "top_company": false,
    "isHiring": false,
    "nonprofit": false,
    "batch": "Summer 2025",
    "status": "Active",
    "industries": [
      "B2B"
    ],
    "regions": [
      "United States of America",
      "America / Canada",
      "Remote",
      "Partly Remote"
    ],
    "stage": "Early",
    "app_video_public": false,
    "demo_day_video_public": false,
    "app_answers": null,
    "question_answers": false,
    "url": "https://www.ycombinator.com/companies/juxta",
    "api": "https://yc-oss.github.io/api/batches/summer-2025/juxta.json"
  }
]
