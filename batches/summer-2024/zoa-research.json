{
  "id": 29731,
  "name": "Zoa Research",
  "slug": "zoa-research",
  "former_names": [
    "Pastel Health",
    "Olive Legal",
    "Paradome"
  ],
  "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/0a603d093e3e3a39d0f3743b7f24486743b3bd06.png",
  "website": "https://zoaresearch.com",
  "all_locations": "New York, NY, USA",
  "long_description": "Historically, quantitative models are domain specific. Brilliant people spend their best years testing features, tuning hyperparameters, and iterating architectures within a narrow domain. But scale is the panacea: large models will find patterns people, and specialized models, could not. \r\n\r\nForecasting generalizes. Zoa trains cross-domain event forecasting engines. \r\n\r\n*Automating Iteration*\r\n\r\nLLMs—embedded in multi-agent optimization loops and evaluated against fixed policies—can automate the build-test-improve modeling cycle. Think AlphaEvolve for forecasting problems.\r\n\r\n*Sample-Efficient General Models*\r\n\r\nToday’s forecasting models are narrowly crafted with deep human priors. But larger models will outperform state-of-the-art specialized models.\r\n\r\nUnlike existing event models, our models leverage data from across contexts and rely less on human intuition. And compared to LLMs, our models are built with more inductive priors and rely more heavily on inference-time compute—improving sample efficiency.\r\n\r\n*Why It Matters*\r\n\r\nIn the real economy, our models could be useful for forecasting supply chain volatility, energy supply and demand, even earthquake risk.\r\n\r\nScience is, Ian Hacking writes, the taming of chance. It is the process of iteratively updating priors (something like: identify uncertainty, conceive experiment to reduce uncertainty, execute, update). If science is uncertainty-reduction, forecasting is a critical measure of progress. \r\n\r\nBetter forecasting improves our ability to select interesting experiments (roughly those with greatest expected uncertainty reduction) and update priors. Our models will be used by labs and academics in data-heavy domains. \r\n\r\nSam's ex-girlfriend introduced him to Greg back at Carnegie Mellon in 2017, and while that relationship didn't last, their friendship has. After college, Greg went to Harvard Law School, while Sam worked for three years at Jane Street on their Options desk, building & leading a satellite dev team.",
  "one_liner": "Powerful quantitative forecasting models",
  "team_size": 5,
  "industry": "B2B",
  "subindustry": "B2B",
  "launched_at": 1724859181,
  "tags": [
    "Data Science",
    "AI"
  ],
  "tags_highlighted": [],
  "top_company": false,
  "isHiring": true,
  "nonprofit": false,
  "batch": "Summer 2024",
  "status": "Active",
  "industries": [
    "B2B"
  ],
  "regions": [
    "United States of America",
    "America / Canada"
  ],
  "stage": "Early",
  "app_video_public": false,
  "demo_day_video_public": false,
  "app_answers": null,
  "question_answers": false,
  "url": "https://www.ycombinator.com/companies/zoa-research",
  "api": "https://yc-oss.github.io/api/batches/summer-2024/zoa-research.json"
}
