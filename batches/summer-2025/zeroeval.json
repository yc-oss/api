{
  "id": 30625,
  "name": "ZeroEval",
  "slug": "zeroeval",
  "former_names": [],
  "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/d7ecfb758177e9198eb8221c46198150c3a277ba.png",
  "website": "https://zeroeval.com",
  "all_locations": "New York, NY, USA",
  "long_description": "We help companies build reliable AI agents through an evaluation harness that learns over time using human feedback. \r\n\r\n\r\n1. The problem:\r\n\r\nCurrent offline eval methods are high-friction, a lot of work is needed to continuously curate labeled data, write experiments and evaluators. \r\n\r\nOn the other hand, current LLM judges are static and often have terrible performance, they lack context on how they fail and the nuances of the task at hand. \r\n\r\n\r\n2. The solution:\r\n\r\nWe're building new evaluation tools that provide signal faster and of higher quality than traditional evals.\r\n\r\n- Calibrated Judges: LLM Judges that learn from their mistakes and get better over time.\r\n\r\n- Autotune: Automatic evals with dozens of models and optimization (genetic prompt tuning & sft).\r\n\r\n- Arenas: Pairwise comparison and ELO rankings of agents with subjective outputs like UI generation, motion design, etc.\r\n\r\nDo you have tool call failures? Hallucinations? Outputs that you don't like? Talk to us.\r\n\r\n\r\n\r\n",
  "one_liner": "A tool to evaluate and optimize AI agents using human feedback.",
  "team_size": 2,
  "industry": "B2B",
  "subindustry": "B2B",
  "launched_at": 1755052091,
  "tags": [
    "AIOps",
    "Artificial Intelligence",
    "Developer Tools",
    "Generative AI",
    "SaaS"
  ],
  "tags_highlighted": [],
  "top_company": false,
  "isHiring": false,
  "nonprofit": false,
  "batch": "Summer 2025",
  "status": "Active",
  "industries": [
    "B2B"
  ],
  "regions": [
    "United States of America",
    "America / Canada"
  ],
  "stage": "Early",
  "app_video_public": false,
  "demo_day_video_public": false,
  "app_answers": null,
  "question_answers": false,
  "url": "https://www.ycombinator.com/companies/zeroeval",
  "api": "https://yc-oss.github.io/api/batches/summer-2025/zeroeval.json"
}
