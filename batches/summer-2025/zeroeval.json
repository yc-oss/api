{
  "id": 30625,
  "name": "ZeroEval",
  "slug": "zeroeval",
  "former_names": [],
  "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/d7ecfb758177e9198eb8221c46198150c3a277ba.png",
  "website": "https://zeroeval.com",
  "all_locations": "New York, NY, USA",
  "long_description": "We help companies build reliable AI agents through an evaluation harness that learns over time using human feedback.\r\n\r\nThe biggest issue with traditional eval tooling is that they are not fit to evaluate more complex situations like:\r\n- Long running, multi-turn agents with dozens of intermediate tool calls.\r\n- Generalist agents that have no clear (input) / (expected output) but can sometimes feel “wrong”.\r\n- Images, video, UI, personality, taste, etc\r\n\r\nOverall: Things that are difficult to verify programatically.\r\n\r\nWith ZeroEval we are building a way to back-propagate your AI agent's errors and help you optimize your most important metric.\r\n\r\nCurrent LLM judges are static and unreliable when it comes to evaluating complex systems. One way we are solving is through calibrated judges that learn through their mistakes and get better over time. Having a reliable judge is the highest leverage piece any company building with AI can have.\r\n\r\nOur mission is to enable every company to build reliable, self-improving AI software.",
  "one_liner": "A platform to measure the quality of AI agents using human feedback.",
  "team_size": 2,
  "industry": "B2B",
  "subindustry": "B2B",
  "launched_at": 1755052091,
  "tags": [
    "AIOps",
    "Artificial Intelligence",
    "Developer Tools",
    "Generative AI",
    "SaaS"
  ],
  "tags_highlighted": [],
  "top_company": false,
  "isHiring": false,
  "nonprofit": false,
  "batch": "Summer 2025",
  "status": "Active",
  "industries": [
    "B2B"
  ],
  "regions": [
    "United States of America",
    "America / Canada"
  ],
  "stage": "Early",
  "app_video_public": true,
  "demo_day_video_public": false,
  "app_answers": null,
  "question_answers": false,
  "url": "https://www.ycombinator.com/companies/zeroeval",
  "api": "https://yc-oss.github.io/api/batches/summer-2025/zeroeval.json"
}
