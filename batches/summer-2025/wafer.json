{
  "id": 30644,
  "name": "Wafer",
  "slug": "wafer",
  "former_names": [],
  "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/61e67ddaa1d4587866c39e69423b9cbe84663f41.png",
  "website": "https://www.wafer.ai",
  "all_locations": "San Francisco, CA, USA",
  "long_description": "Host AI models on custom infrastructure optimized for time-sensitive applications. Custom Trained Models, Dedicated Infrastructure, and Protected Data.\r\n\r\nWe provide scalable compute, optimized inference engines, intelligent routing and autoscaling, real-time observability, and kernel-level performance optimizations, with strict SLAs and white-glove support. \r\n\r\nHerdora's long-term bet is maximizing intelligence per watt.\r\n\r\nAI is clearly going to be everywhere. The constraint won't be what models can do, but how much intelligence we can afford to run. \r\n\r\nMost companies waste enormous compute running inference inefficiently. They use the wrong models, bad serving stacks, and infrastructure that wasn't built for their actual workload. We focus on serving enterprises that need the best performance and reliability in the world while keeping control and visibility.",
  "one_liner": "Optimized AI Inference. Custom Built for Your Stack.",
  "team_size": 2,
  "industry": "B2B",
  "subindustry": "B2B -> Engineering, Product and Design",
  "launched_at": 1751530242,
  "tags": [
    "AI"
  ],
  "tags_highlighted": [],
  "top_company": false,
  "isHiring": true,
  "nonprofit": false,
  "batch": "Summer 2025",
  "status": "Active",
  "industries": [
    "B2B",
    "Engineering, Product and Design"
  ],
  "regions": [
    "United States of America",
    "America / Canada"
  ],
  "stage": "Early",
  "app_video_public": false,
  "demo_day_video_public": false,
  "app_answers": null,
  "question_answers": false,
  "url": "https://www.ycombinator.com/companies/wafer",
  "api": "https://yc-oss.github.io/api/batches/summer-2025/wafer.json"
}
