{
  "id": 28812,
  "name": "Cedana",
  "slug": "cedana",
  "former_names": [],
  "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/16f24156219bac0f48e878f7b176d11721bc6958.png",
  "website": "https://cedana.ai",
  "all_locations": "New York, NY, USA; Remote",
  "long_description": "Cedana (YC S23) brings hyperscaler and frontier-lab orchestration capabilities for AI workflows. Our core capability is live migration for CPUs and GPUs workloads. This increases cost savings up to 80%, accelerates time to first token 2-10x, and enables stateful reliability of training jobs even through catastrophic GPU failures. We've integrated our solution into K8s, and support Kueue and Slurm for training distributed jobs, and Kserve for serving inference.    \r\n\r\nOpenAI, Meta and Microsoft have flavors of these capabilities internally and we’re bringing them to everyone. \r\n\r\nOur vision is to transform cloud compute into a real-time, arbitraged commodity. \r\n\r\nhttps://www.cedana.ai",
  "one_liner": "Fast, reliable, reproducible AI with GPU live migration",
  "team_size": 5,
  "industry": "B2B",
  "subindustry": "B2B -> Infrastructure",
  "launched_at": 1689189501,
  "tags": [
    "Artificial Intelligence",
    "Deep Learning",
    "Developer Tools",
    "Cloud Computing",
    "Infrastructure"
  ],
  "tags_highlighted": [],
  "top_company": false,
  "isHiring": true,
  "nonprofit": false,
  "batch": "Summer 2023",
  "status": "Active",
  "industries": [
    "B2B",
    "Infrastructure"
  ],
  "regions": [
    "United States of America",
    "America / Canada",
    "Remote",
    "Fully Remote"
  ],
  "stage": "Early",
  "app_video_public": false,
  "demo_day_video_public": false,
  "app_answers": null,
  "question_answers": false,
  "url": "https://www.ycombinator.com/companies/cedana",
  "api": "https://yc-oss.github.io/api/batches/summer-2023/cedana.json"
}
