{
  "id": 30284,
  "name": "Exla",
  "slug": "exla",
  "former_names": [],
  "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/94cd00784e37842fc455ee2fd7b22d487b0693cf.png",
  "website": "https://exla.ai/",
  "all_locations": "",
  "long_description": "Exla aggressively quantizes AI models to minimize memory usage and maximize inference speed. Whether you're deploying LLMs, VLMs, VLAs, or custom models, Exla reduces memory footprint by up to 80% and accelerates inference by 3â€“20x - all with just a few lines of code.\r\n\r\nhttps://cal.com/exla-ai/schedule",
  "one_liner": "An SDK to run transformer models anywhere",
  "team_size": 0,
  "industry": "B2B",
  "subindustry": "B2B -> Engineering, Product and Design",
  "launched_at": 1740012412,
  "tags": [
    "Edge Computing Semiconductors",
    "Computer Vision",
    "AI"
  ],
  "tags_highlighted": [],
  "top_company": false,
  "isHiring": false,
  "nonprofit": false,
  "batch": "Winter 2025",
  "status": "Active",
  "industries": [
    "B2B",
    "Engineering, Product and Design"
  ],
  "regions": [
    "Unspecified"
  ],
  "stage": "Early",
  "app_video_public": false,
  "demo_day_video_public": false,
  "app_answers": null,
  "question_answers": false,
  "url": "https://www.ycombinator.com/companies/exla",
  "api": "https://yc-oss.github.io/api/batches/winter-2025/exla.json"
}
